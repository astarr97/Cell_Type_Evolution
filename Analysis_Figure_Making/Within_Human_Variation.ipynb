{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4fa0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import re\n",
    "from scipy.stats.stats import pearsonr\n",
    "#import rpy2.robjects as robjects\n",
    "import random\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "import copy\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "from scipy.stats import binom_test\n",
    "import gseapy as gs\n",
    "import gzip\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1b568d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meta = pd.read_csv(\"PEC2_sample_metadata.txt\", sep = \"\\t\")\n",
    "meta = meta[meta[\"Cohort\"].isin([\"CMC\", \"LIBD\", \"UCLA-ASD\", \"ROSMAP\", \"SZBDMulti-Seq\"])]\n",
    "meta = meta[meta[\"Disorder\"].isin([\"control\", \"Control\"])]\n",
    "meta = meta[meta[\"1000G_ancestry\"].isin([\"EUR\"])]\n",
    "meta = meta[meta[\"Age_death\"].astype(int) >= 25]\n",
    "keep_inds = list(meta[\"Individual_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3383f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate through all the expression matrices\n",
    "df_all = pd.DataFrame()\n",
    "ind = 1\n",
    "c = 0\n",
    "for folder in os.listdir(\"snrna_expr_matrices/snrna_expr_matrices\"):\n",
    "    for file in os.listdir(\"snrna_expr_matrices/snrna_expr_matrices/\" + folder):\n",
    "        with gzip.open('snrna_expr_matrices/snrna_expr_matrices/' + folder + \"/\" + file, 'rt') as f:\n",
    "            line = f.readline()\n",
    "            indiv = file.replace(\"-annotated_matrix.txt.gz\", \"\")\n",
    "            ctd = Counter(line.replace(\"\\n\", \"\").split(\"\\t\"))\n",
    "            df_ind = pd.DataFrame.from_dict(ctd, orient='index')\n",
    "            df_ind.columns = [indiv]\n",
    "            if indiv in keep_inds:\n",
    "                c += 1\n",
    "                if ind:\n",
    "                    ind = 0\n",
    "                    df_all = df_ind\n",
    "                else:\n",
    "                    df_all = df_all.join(df_ind, how = \"outer\")\n",
    "\n",
    "df_all = df_all.replace(np.nan, 0)\n",
    "out = []\n",
    "for index, row in df_all.iterrows():\n",
    "    s = 0\n",
    "    for i in list(row):\n",
    "        if i >= 50:\n",
    "            s += 1\n",
    "    out.append([index, s])\n",
    "above_50 = pd.DataFrame(out)\n",
    "above_50.sort_values(1)\n",
    "\n",
    "#Cell types to include based on the above analysis computing how many cells are in each dataset\n",
    "include = [\"Sncg\", \"L5/6 NP\", \"Lamp5 Lhx6\", \"L6b\", \"L6 CT\", \"Lamp5\", \"Sst\", \"Vip\", \"Pvalb\", \"L4 IT\", \"L6 IT\", \"L5 IT\", \"L2/3 IT\"]\n",
    "\n",
    "#Keep only the ones with enough cells per cell type\n",
    "c = 0\n",
    "keep_samp = []\n",
    "for folder in os.listdir(\"snrna_expr_matrices/snrna_expr_matrices\"):\n",
    "    for file in os.listdir(\"snrna_expr_matrices/snrna_expr_matrices/\" + folder):\n",
    "        with gzip.open('snrna_expr_matrices/snrna_expr_matrices/' + folder + \"/\" + file, 'rt') as f:\n",
    "            line = f.readline()\n",
    "            indiv = file.replace(\"-annotated_matrix.txt.gz\", \"\")\n",
    "            ctd = Counter(line.replace(\"\\n\", \"\").split(\"\\t\"))\n",
    "            df_ind = pd.DataFrame.from_dict(ctd, orient='index')\n",
    "            df_ind.columns = [indiv]\n",
    "            if len(np.intersect1d(include, df_ind.index)) == len(include) and indiv in keep_inds:\n",
    "                c += 1\n",
    "                df_ind = df_ind.loc[include]\n",
    "                if np.min(df_ind[indiv]) >= 50:\n",
    "                    keep_samp.append(file)\n",
    "keep_genes = list(pd.read_csv(\"Human_Sestan_DLPFC_SampSize_1000_Round100.txt\", sep = \"\\t\")[\"0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25242625",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downsample counts and number of cells\n",
    "for folder in os.listdir(\"snrna_expr_matrices/snrna_expr_matrices\"):\n",
    "    for file in os.listdir(\"snrna_expr_matrices/snrna_expr_matrices/\" + folder):\n",
    "        if file in keep_samp and file.replace(\"-annotated_matrix.txt.gz\", \"\") not in done:\n",
    "            print(file)\n",
    "            v = pd.read_csv('snrna_expr_matrices/snrna_expr_matrices/' + folder + \"/\" + file, sep = \"\\t\")\n",
    "            v = v.set_index(\"featurekey\")\n",
    "            cts = np.array([x.split(\".\")[0] for x in v.columns])\n",
    "            v.columns = list(range(len(v.columns)))\n",
    "            v = v.loc[np.intersect1d(keep_genes, v.index)]\n",
    "            for ite in range(11, 101):\n",
    "                np.random.seed(ite)\n",
    "                ind = 1\n",
    "                pseudo_all = pd.DataFrame()\n",
    "                for ct in include:\n",
    "                    inds = np.where(np.array(cts) == ct)[0]\n",
    "                    keep_inds = np.random.choice(inds, replace = False, size = 50)\n",
    "                    v_samp = v[keep_inds]\n",
    "                    pseudo = pd.DataFrame(v_samp.sum(axis = 1))\n",
    "                    pseudo.columns = [ct]\n",
    "                    if ind:\n",
    "                        ind = 0\n",
    "                        pseudo_all = pseudo\n",
    "                    else:\n",
    "                        pseudo_all = pseudo_all.join(pseudo, how = \"outer\")\n",
    "                pseudo_all = pseudo_all.replace(np.nan, 0)\n",
    "                pseudo_all.to_csv(\"Downsamplings_Control/\" + file.replace(\".txt.gz\", \"\") + \"_Size50_Round\" + str(ite) + \".txt\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed998af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rewriting keep_indiv here\n",
    "keep_indiv = ['CMC_MSSM_049-annotated_matrix.txt.gz', 'CMC_MSSM_056-annotated_matrix.txt.gz', 'CMC_MSSM_089-annotated_matrix.txt.gz', 'CMC_MSSM_227-annotated_matrix.txt.gz',\\\n",
    " 'CMC_MSSM_234-annotated_matrix.txt.gz',\\\n",
    " 'CMC_MSSM_272-annotated_matrix.txt.gz',\\\n",
    " 'CON1-annotated_matrix.txt.gz',\\\n",
    " 'CON11-annotated_matrix.txt.gz',\\\n",
    " 'CON12-annotated_matrix.txt.gz',\\\n",
    " 'CON13-annotated_matrix.txt.gz',\\\n",
    " 'CON15-annotated_matrix.txt.gz',\\\n",
    " 'CON16-annotated_matrix.txt.gz',\\\n",
    " 'CON18-annotated_matrix.txt.gz',\\\n",
    " 'CON19-annotated_matrix.txt.gz',\\\n",
    " 'CON20-annotated_matrix.txt.gz',\\\n",
    " 'CON21-annotated_matrix.txt.gz',\\\n",
    " 'CON23-annotated_matrix.txt.gz',\\\n",
    " 'CON3-annotated_matrix.txt.gz',\\\n",
    " 'CON4-annotated_matrix.txt.gz',\\\n",
    " 'CON5-annotated_matrix.txt.gz',\\\n",
    " 'CON6-annotated_matrix.txt.gz',\\\n",
    " 'CON9-annotated_matrix.txt.gz',\\\n",
    " '75QW-annotated_matrix.txt.gz',\\\n",
    " 'AN19760-annotated_matrix.txt.gz',\\\n",
    " 'HctZGA002-annotated_matrix.txt.gz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba664e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making keep_samp again just in case\n",
    "keep_samp = [x.replace(\"-annotated_matrix.txt.gz\", \"\") for x in list(keep_indiv)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4769b2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute cell type proportions\n",
    "include = [\"Sncg\", \"L5/6 NP\", \"Lamp5 Lhx6\", \"L6b\", \"L6 CT\", \"Lamp5\", \"Sst\", \"Vip\", \"Pvalb\", \"L4 IT\", \"L6 IT\", \"L5 IT\", \"L2/3 IT\"]\n",
    "\n",
    "v = pd.read_csv(\"CellTypeNumbers_388.csv\")\n",
    "v = v.set_index(\"individualID\").loc[keep_samp]\n",
    "out = []\n",
    "for i in include:\n",
    "    v2 = v[v[\"CellType\"].isin([i])]\n",
    "    out.append([i, np.sum(v2[\"counts\"])])\n",
    "df_prop = pd.DataFrame(out)\n",
    "df_prop.columns = [\"Cell type\", \"Counts\"]\n",
    "df_prop[\"Proportion\"] = df_prop[\"Counts\"]/np.sum(df_prop[\"Counts\"])\n",
    "df_prop = df_prop.set_index(\"Cell type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594721ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Go through and compute median correlation of within human variance with cell type proportion \n",
    "#Save iteration 2 as it is the first iteration that has the median correlation\n",
    "plt.rcParams['xtick.major.size'] = 10\n",
    "plt.rcParams['xtick.major.width'] = 1.5\n",
    "plt.rcParams['xtick.minor.size'] = 4\n",
    "plt.rcParams['xtick.minor.width'] = 1\n",
    "plt.rcParams['xtick.bottom'] = True\n",
    "plt.rcParams['ytick.left'] = True\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "def downsample_counts(x, min_counts, iteration):\n",
    "    prob = x/np.sum(x)\n",
    "    np.random.seed(iteration)\n",
    "    return np.random.multinomial(n=min_counts, pvals = prob, size = 1)[0]\n",
    "\n",
    "def cpm(x):\n",
    "    return x/np.sum(x)*1000000\n",
    "\n",
    "include = [\"Sncg\", \"L5/6 NP\", \"Lamp5 Lhx6\", \"L6b\", \"L6 CT\", \"Lamp5\", \"Sst\", \"Vip\", \"Pvalb\", \"L4 IT\", \"L6 IT\", \"L5 IT\", \"L2/3 IT\"]\n",
    "import os\n",
    "final_out = []\n",
    "df_save = 0\n",
    "for iteration in range(1, 101):\n",
    "    ind = 1\n",
    "    df = 0\n",
    "    for file in os.listdir(\"Downsamplings_Control\"):\n",
    "        if \"Round\" + str(iteration) + \".txt\" in file:\n",
    "            v = pd.read_csv(\"Downsamplings_Control/\" + file, sep = \"\\t\").set_index(\"featurekey\")\n",
    "            v.columns = [x + \"-\" + file.replace(\"-annotated_matrix_Size50_Round\" + str(iteration) + \".txt\", \"\") for x in list(v.columns)]\n",
    "            lowest_counts = np.min(np.sum(v))\n",
    "            v = v.apply(downsample_counts, axis = 0, min_counts = lowest_counts, iteration = 1)\n",
    "            check = []\n",
    "            for q in v.columns:\n",
    "                check.append(np.sum(v[q]))\n",
    "            assert(len(set(check)) == 1)\n",
    "            if ind:\n",
    "                df = v.copy()\n",
    "                ind = 0\n",
    "            else:\n",
    "                df = df.join(v, how = \"outer\")\n",
    "    out = []\n",
    "    for i in include:\n",
    "        keep_cols = []\n",
    "        for j in list(df.columns):\n",
    "            if i in j:\n",
    "                keep_cols.append(j)\n",
    "        df_cur = df[keep_cols].copy()\n",
    "        df_cur[\"Mean\"] = np.mean(df_cur, axis = 1)\n",
    "        df_cur = df_cur[df_cur[\"Mean\"] >= 25]\n",
    "        df_cur = df_cur.drop(\"Mean\", axis = 1)\n",
    "        df_cur = df_cur.apply(cpm, axis = 0)\n",
    "        centroid = np.mean(df_cur, axis = 1)\n",
    "        rhos = []\n",
    "        for j in keep_cols:\n",
    "            rhos.append(spearmanr(df_cur[j], centroid)[0])\n",
    "        out.append([i, np.mean(rhos), np.median(rhos)])\n",
    "    df_plot = pd.DataFrame(out)\n",
    "    df_plot.columns = [\"Cell type\", \"Mean\", \"Median\"]\n",
    "    \n",
    "    df_plot = df_plot.set_index(\"Cell type\")\n",
    "    df_plot = df_plot.join(df_prop)\n",
    "    if iteration == 2:\n",
    "        df_save = df_plot.copy()\n",
    "    spear = spearmanr(np.log10(df_plot[\"Proportion\"]), 1-df_plot[\"Mean\"])\n",
    "    final_out.append([iteration, spear[0], spear[1]])\n",
    "df = pd.DataFrame(final_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67333071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write out iteration 2 for plotting later\n",
    "df_save.to_csv(\"WithinHuman_ToPlot.txt\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a9ec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the median p-vlaue etc.\n",
    "print(np.median(df[1]))\n",
    "print(np.median(df[2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
