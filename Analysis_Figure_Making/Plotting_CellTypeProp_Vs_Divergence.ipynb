{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9430ff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import re\n",
    "#import rpy2.robjects as robjects\n",
    "import random\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "import os\n",
    "import seaborn as sns\n",
    "#import gseapy as gs\n",
    "from scipy.stats import norm\n",
    "import gseapy as gs\n",
    "#import scanpy as sc\n",
    "from collections import Counter\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "#Set the filtering criteria\n",
    "log = \"Log2\"\n",
    "fcpm = 1\n",
    "rf = 25\n",
    "ncells = 250\n",
    "ags = \"NotAllSame\"\n",
    "dc = \"DownCounts\"\n",
    "\n",
    "#Set the plotting parameters\n",
    "palette = {\"All\":\"#0979E6\", \"Exc\":\"#E6710A\", \"Inh\":\"#08C9AC\", \"Excitatory\":\"#E6710A\", \"Inhibitory\":\"#08C9AC\"}\n",
    "palette_strat = {\"High\":\"#EB05A6\", \"Med\":\"#449971\", \"Low\":\"#8FA1EB\", \"No Filt Matched Size\":\"#EBC705\"}\n",
    "palette_strat_cont = {\"Med High\":\"#EB05A6\", \"Low High\":\"#D4004D\", \"Med Med\":\"#449971\", \"Low Low\":\"#8FA1EB\", \"NoFilt Low Size\":\"#EBC705\", \"NoFilt Med Size\":\"#998203\"}\n",
    "shapes = {\"Sestan_DLPFC\":\"s\", \"Allen_MTG\":\"o\", \"Allen_M1\":\"^\"}\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['mathtext.default'] = 'regular'\n",
    "df_save = df_save.sort_values(\"Relative\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fec40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenating the results for Tau because it took two separate runs (only done once and commented out thereafter)\n",
    "\"\"\"v91 = pd.read_csv(\"ExprLevel/Allen_MTG_cross_species_cluster_NotAllSame_DownCounts78-100_General_ContTau_ExprLevel.txt\", sep = \"\\t\")\n",
    "v = pd.read_csv(\"ExprLevel/Allen_MTG_cross_species_cluster_NotAllSame_DownCounts1-100_General_ContTau_ExprLevel.txt\", sep = \"\\t\")\n",
    "v = v[~v[\"Iteration\"].isin(list(range(78, 101)))]\n",
    "v_fixed = pd.concat([v, v91])\n",
    "v_fixed.to_csv(\"ExprLevel/Allen_MTG_cross_species_cluster_NotAllSame_DownCounts1-100_General_ContTau_ExprLevel.txt\", sep = \"\\t\", index = False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b70b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"file = \"Sestan_DLPFC_subtype_AllSame_DownCounts1-100_General_ContExp_Tau_distances.txt\"\n",
    "v = pd.read_csv(\"Tau/\" + file, sep = \"\\t\")\n",
    "v[\"Distance l1\"] = v[\"Distance euclidean\"]\n",
    "v[\"Distance euclidean\"] = v[\"Distance pearson\"]\n",
    "v[\"Distance pearson\"] = v[\"Distance spearman\"]\n",
    "v[\"Distance spearman\"] = v[\"Tau filt value\"]\n",
    "v = v.drop(\"Tau filt value\", axis= 1)\n",
    "v.to_csv(\"Tau/\" + file, sep = \"\\t\", index = False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd034c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"file = \"Sestan_DLPFC_subtype_NotAllSame_DownCounts1-100_General_ContExp_Tau_distances.txt\"\n",
    "v = pd.read_csv(\"Tau/\" + file, sep = \",\")\n",
    "v = v.drop(\"Unnamed: 0\", axis = 1)\n",
    "v_sub = v[~v[\"Iteration\"].isin([91, 92, 93, 94, 95, 96, 97, 98, 99, 100])]\n",
    "v_sub2 = v[v[\"Iteration\"].isin([91, 92, 93, 94, 95, 96, 97, 98, 99, 100])]\n",
    "v_sub2 = v_sub2.drop(\"Tau filt value\", axis = 1)\n",
    "v_sub[\"Distance l1\"] = v_sub[\"Distance euclidean\"]\n",
    "v_sub[\"Distance euclidean\"] = v_sub[\"Distance pearson\"]\n",
    "v_sub[\"Distance pearson\"] = v_sub[\"Distance spearman\"]\n",
    "v_sub[\"Distance spearman\"] = v_sub[\"Tau filt value\"]\n",
    "v_sub = v_sub.drop(\"Tau filt value\", axis = 1)\n",
    "v = pd.concat([v_sub, v_sub2])\n",
    "v.to_csv(\"Tau/\" + file, sep = \"\\t\", index = False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac713403",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenating the results for Tau because it took two separate runs (only done once)\n",
    "\"\"\"v91 = pd.read_csv(\"Tau/Sestan_DLPFC_subtype_NotAllSame_DownCounts91-100_General_ContExp_Tau.txt\", sep = \"\\t\")\n",
    "v = pd.read_csv(\"Tau/Sestan_DLPFC_subtype_NotAllSame_DownCounts1-100_General_ContExp_Tau.txt\", sep = \"\\t\")\n",
    "v = v[~v[\"Iteration\"].isin([91, 92, 93, 94, 95, 96, 97, 98, 99, 100])]\n",
    "v_fixed = pd.concat([v, v91])\n",
    "v_fixed.to_csv(\"Tau/Sestan_DLPFC_subtype_NotAllSame_DownCounts1-100_General_ContExp_Tau.txt\", sep = \"\\t\", index = False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eafdd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot interindividual variation across cell types\n",
    "\n",
    "plt.rcParams['xtick.major.size'] = 10\n",
    "plt.rcParams['xtick.major.width'] = 1.5\n",
    "plt.rcParams['xtick.minor.size'] = 4\n",
    "plt.rcParams['xtick.minor.width'] = 1\n",
    "plt.rcParams['xtick.bottom'] = True\n",
    "plt.rcParams['ytick.left'] = True\n",
    "\n",
    "df_save = pd.read_csv(\"WithinHuman_ToPlot.txt\", sep = \"\\t\").set_index(\"Cell type\")\n",
    "df_save[\"Proportion\"] = np.log10(df_save[\"Proportion\"])\n",
    "df_save[\"Mean\"] = 1-df_save[\"Mean\"]\n",
    "sns.set(font_scale = 1.6)\n",
    "sns.set_style(\"white\")\n",
    "fig, ax = plt.subplots(figsize = (7, 5))\n",
    "ax = sns.regplot(data = df_save, x=\"Proportion\", y = \"Mean\", scatter_kws = {\"edgecolors\":\"black\"}, marker = \"D\", color = \"#0979E6\")\n",
    "\n",
    "major_ticks2 = [0.01, 0.1, 0.3]\n",
    "major_ticks = [np.log10(x) for x in major_ticks2]\n",
    "minor_ticks2 = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.2]\n",
    "minor_ticks = [np.log10(x) for x in minor_ticks2]\n",
    "minor_ticks2 = [\"\" for x in minor_ticks2]\n",
    "ax.set_xticks(major_ticks, major_ticks2, minor = False)\n",
    "ax.set_xticks(minor_ticks, minor_ticks2, minor = True)\n",
    "plt.ylim(.1, .17)\n",
    "print(ax.get_xlim())\n",
    "plt.ylabel(\"Interindividual variation\")\n",
    "plt.xlabel(\"Cell type proportion\")\n",
    "plt.title(\"Interindividual variation vs cell type prop.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347b80f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Functions for calculating the statistical significant differences between two dependent or independent correlation\n",
    "coefficients.\n",
    "The Fisher and Steiger method is adopted from the R package http://personality-project.org/r/html/paired.r.html\n",
    "and is described in detail in the book 'Statistical Methods for Psychology'\n",
    "The Zou method is adopted from http://seriousstats.wordpress.com/2012/02/05/comparing-correlations/\n",
    "Credit goes to the authors of above mentioned packages!\n",
    "\n",
    "Author: Philipp Singer (www.philippsinger.info)\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "__author__ = 'psinger'\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import t, norm\n",
    "from math import atanh, pow\n",
    "from numpy import tanh\n",
    "\n",
    "def rz_ci(r, n, conf_level = 0.95):\n",
    "    zr_se = pow(1/(n - 3), .5)\n",
    "    moe = norm.ppf(1 - (1 - conf_level)/float(2)) * zr_se\n",
    "    zu = atanh(r) + moe\n",
    "    zl = atanh(r) - moe\n",
    "    return tanh((zl, zu))\n",
    "\n",
    "def rho_rxy_rxz(rxy, rxz, ryz):\n",
    "    num = (ryz-1/2.*rxy*rxz)*(1-pow(rxy,2)-pow(rxz,2)-pow(ryz,2))+pow(ryz,3)\n",
    "    den = (1 - pow(rxy,2)) * (1 - pow(rxz,2))\n",
    "    return num/float(den)\n",
    "\n",
    "def dependent_corr(xy, xz, yz, n, twotailed=True, conf_level=0.95, method='steiger'):\n",
    "    \"\"\"\n",
    "    Calculates the statistic significance between two dependent correlation coefficients\n",
    "    @param xy: correlation coefficient between x and y\n",
    "    @param xz: correlation coefficient between x and z\n",
    "    @param yz: correlation coefficient between y and z\n",
    "    @param n: number of elements in x, y and z\n",
    "    @param twotailed: whether to calculate a one or two tailed test, only works for 'steiger' method\n",
    "    @param conf_level: confidence level, only works for 'zou' method\n",
    "    @param method: defines the method uses, 'steiger' or 'zou'\n",
    "    @return: t and p-val\n",
    "    \"\"\"\n",
    "    if method == 'steiger':\n",
    "        d = xy - xz\n",
    "        determin = 1 - xy * xy - xz * xz - yz * yz + 2 * xy * xz * yz\n",
    "        av = (xy + xz)/2\n",
    "        cube = (1 - yz) * (1 - yz) * (1 - yz)\n",
    "\n",
    "        t2 = d * np.sqrt((n - 1) * (1 + yz)/(((2 * (n - 1)/(n - 3)) * determin + av * av * cube)))\n",
    "        p = 1 - t.cdf(abs(t2), n - 3)\n",
    "\n",
    "        if twotailed:\n",
    "            p *= 2\n",
    "\n",
    "        return t2, p\n",
    "    elif method == 'zou':\n",
    "        L1 = rz_ci(xy, n, conf_level=conf_level)[0]\n",
    "        U1 = rz_ci(xy, n, conf_level=conf_level)[1]\n",
    "        L2 = rz_ci(xz, n, conf_level=conf_level)[0]\n",
    "        U2 = rz_ci(xz, n, conf_level=conf_level)[1]\n",
    "        rho_r12_r13 = rho_rxy_rxz(xy, xz, yz)\n",
    "        lower = xy - xz - pow((pow((xy - L1), 2) + pow((U2 - xz), 2) - 2 * rho_r12_r13 * (xy - L1) * (U2 - xz)), 0.5)\n",
    "        upper = xy - xz + pow((pow((U1 - xy), 2) + pow((xz - L2), 2) - 2 * rho_r12_r13 * (U1 - xy) * (xz - L2)), 0.5)\n",
    "        return lower, upper\n",
    "    else:\n",
    "        raise Exception('Wrong method!')\n",
    "\n",
    "def independent_corr(xy, ab, n, n2 = None, twotailed=True, conf_level=0.95, method='fisher'):\n",
    "    \"\"\"\n",
    "    Calculates the statistic significance between two independent correlation coefficients\n",
    "    @param xy: correlation coefficient between x and y\n",
    "    @param xz: correlation coefficient between a and b\n",
    "    @param n: number of elements in xy\n",
    "    @param n2: number of elements in ab (if distinct from n)\n",
    "    @param twotailed: whether to calculate a one or two tailed test, only works for 'fisher' method\n",
    "    @param conf_level: confidence level, only works for 'zou' method\n",
    "    @param method: defines the method uses, 'fisher' or 'zou'\n",
    "    @return: z and p-val\n",
    "    \"\"\"\n",
    "\n",
    "    if method == 'fisher':\n",
    "        xy_z = 0.5 * np.log((1 + xy)/(1 - xy))\n",
    "        ab_z = 0.5 * np.log((1 + ab)/(1 - ab))\n",
    "        if n2 is None:\n",
    "            n2 = n\n",
    "\n",
    "        se_diff_r = np.sqrt(1/(n - 3) + 1/(n2 - 3))\n",
    "        diff = xy_z - ab_z\n",
    "        z = abs(diff / se_diff_r)\n",
    "        p = (1 - norm.cdf(z))\n",
    "        if twotailed:\n",
    "            p *= 2\n",
    "\n",
    "        return z, p\n",
    "    elif method == 'zou':\n",
    "        L1 = rz_ci(xy, n, conf_level=conf_level)[0]\n",
    "        U1 = rz_ci(xy, n, conf_level=conf_level)[1]\n",
    "        L2 = rz_ci(ab, n2, conf_level=conf_level)[0]\n",
    "        U2 = rz_ci(ab, n2, conf_level=conf_level)[1]\n",
    "        lower = xy - ab - pow((pow((xy - L1), 2) + pow((U2 - ab), 2)), 0.5)\n",
    "        upper = xy - ab + pow((pow((U1 - xy), 2) + pow((ab - L2), 2)), 0.5)\n",
    "        return lower, upper\n",
    "    else:\n",
    "        raise Exception('Wrong method!')\n",
    "\n",
    "print(dependent_corr(.40, .50, .10, 103, method='steiger'))\n",
    "print(independent_corr(0.5 , 0.6, 103, 103, method='fisher'))\n",
    "\n",
    "#print dependent_corr(.396, .179, .088, 200, method='zou')\n",
    "#print independent_corr(.560, .588, 100, 353, method='zou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfd792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get which cell types to keep when creating plots.\n",
    "def get_ct_keep(data_source, resolution, ctf=\"All\"):\n",
    "    if data_source == \"Sestan_DLPFC\":\n",
    "        \n",
    "        if resolution == \"subclass\":\n",
    "            exclude = [\"RB\", \"PC\", \"OPC\", \"Astro\", \"Micro\", \"Endo\", \"Immune\", \"Oligo\", \"SMC\", \"VLMC\"]\n",
    "            excit = [\"L3-5 IT-1\", \"L2-3 IT\", \"L3-5 IT-3\", \"L6 CT\", \"L6 IT-1\", \"L5-6 NP\", \"L6 IT-2\", \"L3-5 IT-2\", \"L6B\", \"L5 ET\"]\n",
    "            inhib = ['ADARB2 KCNG1', 'LAMP5 LHX6', 'LAMP5 RELN', 'PVALB', 'PVALB ChC', 'SST', 'SST HGF', 'SST NPY', 'VIP']\n",
    "        elif resolution == \"subtype\":\n",
    "            #Additionally exclude two neuronal subtypes not found in all species \n",
    "            #InN LAMP5 SYT10\n",
    "            #L2-3 CUX2 ARHGAP18\n",
    "            exclude = ['InN LAMP5 SYT10', 'L2-3 CUX2 ARHGAP18', 'Astro AQP4 OSMR', 'Astro AQP4 SLC1A2', 'Astro GFAP AQP1', 'Astro GFAP FABP7', 'B EBF1 IGKC', 'COP GPR17 SOX4', 'Endo CLDN5 DKK2', 'Endo CLDN5 IL1R1', 'Endo CLDN5 SLC7A5', 'Macro F13A1 COLEC12', 'Micro P2RY12 APBB1IP', 'Micro P2RY12 CCL3', 'Micro P2RY12 GLDN', 'Myeloid LSP1 LYZ', 'OPC PDGFRA PCDH15', 'Oligo MOG CDH7', 'Oligo MOG FRY', 'Oligo MOG GSN', 'Oligo MOG OPALIN', 'PC P2RY14 GRM8', 'RB HBA1 HBB', 'SMC ACTA2 CNN1', 'SMC ACTA2 CRISPLD2', 'SMC ACTA2 CYP1B1', 'T SKAP1 CD247', 'VLMC COL1A2 SLC13A3', 'VLMC COL1A2 VLMCA8', 'VLMC SLC47A1 SLC4A4']\n",
    "            inhib = ['InN ADARB2 CADPS2', 'InN ADARB2 CALCR', 'InN ADARB2 COL5A2', 'InN ADARB2 FAM19A1', 'InN ADARB2 PALMD', 'InN ADARB2 RGS10', 'InN ADARB2 SFRP2', 'InN LAMP5 ADAMTS20', 'InN LAMP5 BMP7', 'InN LAMP5 LHX6 PROX1', 'InN LAMP5 LHX6 TAC1', 'InN LAMP5 MEIS2', 'InN LAMP5 RELN', 'InN LHX6 HGF STON2', 'InN PVALB ANOS1', 'InN PVALB GRIN2C', 'InN PVALB HPSE', 'InN PVALB PDE3A', 'InN PVALB PIEZO2', 'InN PVALB PRKCH', 'InN PVALB SNTB1', 'InN PVALB SYT2', 'InN SST ADAMTSL1', 'InN SST ADRA1D', 'InN SST ANKRD33B', 'InN SST FREM1', 'InN SST HGF GABRQ', 'InN SST HS3ST5', 'InN SST HTR2C', 'InN SST KLHL14', 'InN SST NPY', 'InN SST PLPP4', 'InN SST STK32A', 'InN SST THSD7B', 'InN SST TRPC7', 'InN VIP ADAM12', 'InN VIP CLSTN2', 'InN VIP EGF', 'InN VIP EXPH5', 'InN VIP FREM2', 'InN VIP HS3ST3B1', 'InN VIP MDGA1', 'InN VIP MEGF11 LHFP', 'InN VIP PENK', 'InN VIP SCML4']\n",
    "            excit = ['L2-3 CUX2 ACVR1C INHBA', 'L2-3 CUX2 ACVR1C THSD7A', 'L2-3 CUX2 NTNG1 COL5A2', 'L2-3 CUX2 NTNG1 PALMD', 'L2-3 CUX2 NTNG1 PLCH1', 'L2-3 CUX2 PLCXD3', 'L2-4 CUX2 RORB CLMN', 'L3-5 RORB GABRG1 KCNH7', 'L3-5 RORB GABRG1 PLCH1', 'L3-5 RORB GABRG1 PTPRO', 'L3-5 RORB MKX DCC', 'L3-5 RORB MKX GALR1', 'L3-5 RORB MKX GRIN3A', 'L3-5 RORB MKX SCN5A', 'L3-5 RORB PCBP3 ARHGAP15', 'L3-5 RORB PCBP3 IL1RAPL2', 'L3-5 RORB PCBP3 LINGO2', 'L3-5 RORB TNNT2 PRRX1', 'L3-5 RORB TNNT2 TSHZ2', 'L5 FEZF2 BCL11B POU3F1', 'L5-6 FEZF2 NXPH2 CDH8', 'L5-6 FEZF2 NXPH2 GPC5', 'L5-6 FEZF2 NXPH2 GRIK1', 'L5-6 FEZF2 NXPH2 SORCS3', 'L6 FEZF2 AMOTL1 CDH6', 'L6 FEZF2 DCBLD1 MITF', 'L6 FEZF2 EYA1', 'L6 FEZF2 HCRTR2 THSD7B', 'L6 FEZF2 NPFFR2 KCNK2', 'L6 FEZF2 NPFFR2 TPD52L1', 'L6 FEZF2 SYT6 CDH9', 'L6 FEZF2 SYT6 ERBB4', 'L6 FEZF2 SYT6 PTPRT', 'L6 FEZF2 SYT6 SULF1', 'L6 OPRK1 SMYD1 ADAMTS17', 'L6 OPRK1 SMYD1 KCND2', 'L6 OPRK1 SMYD1 SNTB1', 'L6 OPRK1 SMYD1 TSHZ2', 'L6 OPRK1 THEMIS RGS6']\n",
    "\n",
    "    elif data_source == \"Allen_M1\":\n",
    "        if resolution == \"subclass\":\n",
    "            exclude = [\"Oligo\", \"Astro\", \"Endo\", \"Micro-PVM\", \"exclude\", \"OPC\", \"VLMC\", \"Peri\", \"SMC\", \"Meis2\"]\n",
    "            excit = [\"L5 IT\", \"L6 CT\", \"L6 IT\", \"L6b\", \"L5/6 NP\", \"L2/3 IT\", \"L5 ET\", \"L6 IT Car3\"]\n",
    "            inhib = ['Lamp5', 'Pvalb', 'Sncg', 'Sst', 'Vip']\n",
    "        elif resolution == \"cross\":\n",
    "            exclude = [\"Oligo_1\", \"Astro_2\", \"Astro_1\", \"Astro\", \"Endo\", \"Microglia/PVM\", \"Oligo_2\", \"exclude\", \"OPC\", \"VLMC\", \"SMC\"]\n",
    "            excit = [\"L5 IT_3\", \"L6 IT_1\", \"L5 ET_1\", \"L6 IT_2\", \"L6 CT_2\", \"L5 ET_2\", \"L5 IT_1\", \"L6 IT_3\", \"L6 CT_1\", \"L6b\", \"L5 IT_2\", \"L5/6 NP\", \"L2/3 IT\"]\n",
    "            inhib = ['Chandelier', 'Lamp5_1', 'Lamp5_2', 'Lamp5_3', 'Lamp5_4', 'Lamp5_5', 'Pvalb_1', 'Pvalb_2', 'Sncg_1', 'Sncg_2', 'Sncg_3', 'Sncg_4', 'Sst Chodl', 'Sst_1', 'Sst_2', 'Sst_3', 'Sst_4', 'Sst_5', 'Sst_6', 'Sst_7', 'Vip_1', 'Vip_2', 'Vip_3', 'Vip_4']\n",
    "    elif data_source == \"Allen_MTG\":\n",
    "        if resolution == \"subclass\":\n",
    "            exclude = [\"Astro\", \"VLMC\", \"Oligo\", \"Micro-PVM\", \"OPC\", \"Endo\"]\n",
    "            excit = ['L6 IT', 'L5 IT', 'L5/6 NP', 'L2/3 IT', 'L4 IT', 'L6 CT', 'L6b', 'L6 IT Car3', 'L5 ET']\n",
    "            inhib = ['Lamp5', 'Chandelier', 'Sst', 'Pvalb', 'Sncg', 'Vip', 'Sst Chodl', 'Lamp5_Lhx6', 'Pax6']\n",
    "        elif resolution == \"cross\":\n",
    "            exclude = ['Astro_1', 'Endo_1', 'OPC_1', 'Oligo_1', 'OPC_2', 'Micro-PVM_1', 'VLMC_1']\n",
    "            excit = ['L6 IT Car3_2', 'L6 IT Car3_1', 'L5 IT_1', 'L6 IT_1', 'L6b_1', 'L6b_3', 'L6 CT_1', 'L6 CT_2', 'L5 ET_2', 'L4 IT_1', 'L4 IT_2', 'L5 ET_1', 'L5/6 NP_2', 'L2/3 IT_2', 'L6b_2', 'L2/3 IT_1', 'L5 IT_2', 'L5/6 NP_1', 'L2/3 IT_3']\n",
    "            inhib = ['Sst Chodl_1', 'Sst_8', 'Sst_7', 'Sst_9', 'Lamp5_Lhx6_1', 'Pax6_1', 'Vip_3', 'Vip_2', 'Sst_6', 'Sst_1', 'Chandelier_1', 'Sst_5', 'Vip_7', 'Sst_4', 'Sst_2', 'Sncg_1', 'Pvalb_2', 'Pax6_2', 'Vip_1', 'Vip_5', 'Lamp5_2', 'Sncg_2', 'Sst_3', 'Vip_6', 'Pvalb_3', 'Sncg_3', 'Pvalb_4', 'Pvalb_1', 'Vip_4', 'Lamp5_1', 'Vip_8']\n",
    "\n",
    "    if ctf == \"All\":\n",
    "        return excit + inhib\n",
    "    elif ctf == \"Inh\":\n",
    "        return inhib\n",
    "    elif ctf == \"Exc\":\n",
    "        return excit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eefc514",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters to sweep through\n",
    "cells = [500, 50, 100, 250]\n",
    "log = [\"NoLog\", \"Log2\"]\n",
    "filt_strats = [5, 1, 25, 50, 0, 10]\n",
    "filt_cpm = [1, 0, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c378acc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only compute the median rho and p-value\n",
    "def just_corr2(v, folder, file, ctf, scomp, log=\"Log2\", fcpm=1, rf=25, ncells=250, ags=\"NotAllSame\", dc=\"DownCounts\", keep_this = \"\", rel_to = \"\", dist_met = \"Spearman\"):\n",
    "    \n",
    "    #Read in file and filter down to only the parameters of interest\n",
    "    \n",
    "    v2 = v[(v[\"Log\"].isin([log])) & (v[\"CPM filtering\"].isin([fcpm])) & (v[\"Raw filtering\"].isin([rf])) & (v[\"Number cells\"].isin([ncells])) & (v[\"All genes same?\"]).isin([ags]) & (v[\"Downsample counts?\"].isin([dc]))]\n",
    "    v2 = v2[(v2[\"Cell type filtering\"].isin([ctf])) & (v2[\"Comparison\"].isin([scomp]))]\n",
    "    if folder == \"Tau\" or folder == \"ExprLevel\" or folder == \"Pritchard\":\n",
    "        if \"NotContExp\" in file or folder == \"ExprLevel\" or \"ContExp\" in file:\n",
    "            v2 = v2[v2[folder].isin([keep_this])]\n",
    "    #Compute median rho and median p-value\n",
    "    median_rho = np.median(v2[\"Spearman correlation dist_met_\" + dist_met.lower()])\n",
    "    median_p = np.median(v2[\"Spearman correlation p-value dist_met_\" + dist_met.lower()])\n",
    "\n",
    "    return median_rho, median_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4efa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### To make supplemental table 1 ###\n",
    "\n",
    "out = []\n",
    "d_conv = {\"Sestan_DLPFC_subtype\":\"Sestan_DLPFC_subtype\", \"Sestan_DLPFC_subclass\":\"Sestan_DLPFC_subclass\", \"Allen_MTG_subclass\":\"Allen_MTG_subclass\", \"Allen_M1_subtype\":\"Allen_M1_cross_species_cluster_label\", \"Allen_M1_subclass\":\"Allen_M1_subclass_label\", \"Allen_MTG_subtype\":\"Allen_MTG_cross_species_cluster\"}\n",
    "d_comp = {\"Allen_M1\":[\"Human-Marmoset\", \"Human-Mouse\", \"Mouse-Marmoset\"], \"Sestan_DLPFC\":[\"Human-Marmoset\", \"Human-Rhesus\", \"Human-Chimpanzee\", \"Rhesus-Chimpanzee\", \"Rhesus-Marmoset\", \"Chimpanzee-Marmoset\"], \\\n",
    "         \"Allen_MTG\":[\"Human-Marmoset\", \"Human-Rhesus\", \"Human-Gorilla\", \"Human-Chimp\", \"Rhesus-Gorilla\", \"Rhesus-Chimp\", \"Rhesus-Marmoset\", \"Gorilla-Chimp\", \"Gorilla-Marmoset\", \"Chimp-Marmoset\"]}\n",
    "\n",
    "cells = [500, 50, 100, 250]\n",
    "log = [\"NoLog\", \"Log2\"]\n",
    "filt_strats = [5, 25, 50, 10]\n",
    "filt_cpm = [1, 5]\n",
    "\n",
    "for ds in [\"Allen_MTG\", \"Allen_M1\", \"Sestan_DLPFC\"]:\n",
    "    for ct in [\"subclass\", \"subtype\"]:\n",
    "        for ags in [\"NotAllSame\", \"AllSame\"]:\n",
    "            comps = d_comp[ds]\n",
    "            prefix = d_conv[ds + \"_\" + ct]\n",
    "            print(ds + \"_\" + ct)\n",
    "            folder = \"Vanilla\"\n",
    "            file = prefix + \"_\" + ags + \"_DownCounts1-100_General.txt\"\n",
    "            v = pd.read_csv(folder + \"/\" + file, sep = \"\\t\")\n",
    "            for ct_filter in [\"All\", \"Exc\", \"Inh\"]:\n",
    "                for cell_num in cells:\n",
    "                    for log_strat in log:\n",
    "                        for filt_strat in filt_strats:\n",
    "                            for cpm_filt_strat in filt_cpm:\n",
    "                                for comp in comps:\n",
    "                                    for dist_met in [\"Spearman\", \"Pearson\", \"Euclidean\", \"L1\"]:\n",
    "                                        mr, mp = just_corr2(v, folder, file, ct_filter, comp, log=log_strat, fcpm=cpm_filt_strat, rf=filt_strat, ncells = cell_num, ags = ags, dist_met = dist_met)\n",
    "                                        #print([ct, ds, ct_filter, comp, cell_num, log_strat, filt_strat, cpm_filt_strat, ags])\n",
    "                                        out.append([ct, ds, ct_filter, comp, cell_num, log_strat, filt_strat, cpm_filt_strat, ags, dist_met, mr, mp])\n",
    "df = pd.DataFrame(out)\n",
    "df.columns = [\"Clustering resolution\", \"Dataset\", \"Class\", \"Comparison\", \"Number of cells\", \"Log transform\", \"Raw count cutoff\", \"CPM cutoff\", \"All genes same?\", \"Distance metric to compare expression\", \"Median Spearman's rho\", \"Median Spearman's p-value\"]\n",
    "df.to_csv(\"Supplemental_Table1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebd60de",
   "metadata": {},
   "outputs": [],
   "source": [
    "### To make supplemental table 2 ###\n",
    "\n",
    "out = []\n",
    "d_conv = {\"Sestan_DLPFC_subtype\":\"Sestan_DLPFC_subtype\", \"Sestan_DLPFC_subclass\":\"Sestan_DLPFC_subclass\", \"Allen_MTG_subclass\":\"Allen_MTG_subclass\", \"Allen_M1_subtype\":\"Allen_M1_cross_species_cluster_label\", \"Allen_M1_subclass\":\"Allen_M1_subclass_label\", \"Allen_MTG_subtype\":\"Allen_MTG_cross_species_cluster\"}\n",
    "d_comp = {\"Allen_M1\":[\"Human-Marmoset\", \"Human-Mouse\", \"Mouse-Marmoset\"], \"Sestan_DLPFC\":[\"Human-Marmoset\", \"Human-Rhesus\", \"Human-Chimpanzee\", \"Rhesus-Chimpanzee\", \"Rhesus-Marmoset\", \"Chimpanzee-Marmoset\"], \\\n",
    "         \"Allen_MTG\":[\"Human-Marmoset\", \"Human-Rhesus\", \"Human-Gorilla\", \"Human-Chimp\", \"Rhesus-Gorilla\", \"Rhesus-Chimp\", \"Rhesus-Marmoset\", \"Gorilla-Chimp\", \"Gorilla-Marmoset\", \"Chimp-Marmoset\"]}\n",
    "\n",
    "cells = [500, 50, 100, 250]\n",
    "log = [\"Log2\"]\n",
    "filt_strats = [10 ,25]\n",
    "filt_cpm = [1, 5]\n",
    "\n",
    "for cont in [\"ContTau_\", \"\"]:\n",
    "    if cont:\n",
    "        cont_write = \"Yes\"\n",
    "    else:\n",
    "        cont_write = \"No\"\n",
    "    for ds in [\"Allen_MTG\", \"Allen_M1\", \"Sestan_DLPFC\"]:\n",
    "        for ct in [\"subclass\", \"subtype\"]:\n",
    "            for ags in [\"NotAllSame\", \"AllSame\"]:\n",
    "                comps = d_comp[ds]\n",
    "                prefix = d_conv[ds + \"_\" + ct]\n",
    "                print(ds + \"_\" + ct)\n",
    "                folder = \"ExprLevel\"\n",
    "                file = prefix + \"_\" + ags + \"_DownCounts1-100_General_\" + cont + folder + \".txt\"\n",
    "                v = pd.read_csv(folder + \"/\" + file, sep = \"\\t\")\n",
    "                for ct_filter in [\"All\", \"Exc\", \"Inh\"]:\n",
    "                    for cell_num in cells:\n",
    "                        for log_strat in log:\n",
    "                            for filt_strat in filt_strats:\n",
    "                                for cpm_filt_strat in filt_cpm:\n",
    "                                    for comp in comps:\n",
    "                                        for dist_met in [\"Euclidean\", \"L1\"]:\n",
    "                                            if cont:\n",
    "                                                types = [\"Med High\", \"Med Med\", \"Low High\", \"Low Low\", \"NoFilt Low Size\", \"NoFilt Med Size\"]\n",
    "                                            else:\n",
    "                                                types = [\"High\", \"Med\", \"Low\", \"No Filt Matched Size\"]\n",
    "                                            for keep_this_t in types:\n",
    "                                                mr, mp = just_corr2(v, folder, file, ct_filter, comp, log=log_strat, fcpm=cpm_filt_strat, rf=filt_strat, ncells = cell_num, ags = ags, dist_met = dist_met, keep_this = keep_this_t)\n",
    "                                                #print([ct, ds, ct_filter, comp, cell_num, log_strat, filt_strat, cpm_filt_strat, ags, dist_met, cont, keep_this_t, mr, mp])\n",
    "                                                out.append([ct, ds, ct_filter, comp, cell_num, log_strat, filt_strat, cpm_filt_strat, ags, dist_met, cont_write, keep_this_t, mr, mp])\n",
    "df = pd.DataFrame(out)\n",
    "df.columns = [\"Clustering resolution\", \"Dataset\", \"Class\", \"Comparison\", \"Number of cells\", \"Log transform\", \"Raw count cutoff\", \"CPM cutoff\", \"All genes same?\", \"Distance metric to compare expression\", \"Control for tau?\", \"Expression level bin\", \"Median Spearman's rho\", \"Median Spearman's p-value\"]\n",
    "df.to_csv(\"Supplemental_Table2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e282f7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### To make supplemental table 3 ###\n",
    "\n",
    "out = []\n",
    "d_conv = {\"Sestan_DLPFC_subtype\":\"Sestan_DLPFC_subtype\", \"Sestan_DLPFC_subclass\":\"Sestan_DLPFC_subclass\", \"Allen_MTG_subclass\":\"Allen_MTG_subclass\", \"Allen_M1_subtype\":\"Allen_M1_cross_species_cluster_label\", \"Allen_M1_subclass\":\"Allen_M1_subclass_label\", \"Allen_MTG_subtype\":\"Allen_MTG_cross_species_cluster\"}\n",
    "d_comp = {\"Allen_M1\":[\"Human-Marmoset\", \"Human-Mouse\", \"Mouse-Marmoset\"], \"Sestan_DLPFC\":[\"Human-Marmoset\", \"Human-Rhesus\", \"Human-Chimpanzee\", \"Rhesus-Chimpanzee\", \"Rhesus-Marmoset\", \"Chimpanzee-Marmoset\"], \\\n",
    "         \"Allen_MTG\":[\"Human-Marmoset\", \"Human-Rhesus\", \"Human-Gorilla\", \"Human-Chimp\", \"Rhesus-Gorilla\", \"Rhesus-Chimp\", \"Rhesus-Marmoset\", \"Gorilla-Chimp\", \"Gorilla-Marmoset\", \"Chimp-Marmoset\"]}\n",
    "\n",
    "#cells = [500, 50, 100, 250]\n",
    "cells = [100, 50, 500, 250]\n",
    "log = [\"Log2\"]\n",
    "filt_strats = [10 ,25]\n",
    "filt_cpm = [1, 5]\n",
    "\n",
    "for cont in [\"NotContExp_\", \"ContExp_\"]:\n",
    "    if \"Not\" not in cont:\n",
    "        cont_write = \"Yes\"\n",
    "    else:\n",
    "        cont_write = \"No\"\n",
    "    for ds in [\"Allen_MTG\", \"Allen_M1\", \"Sestan_DLPFC\"]:\n",
    "        for ct in [\"subclass\", \"subtype\"]:\n",
    "            for ags in [\"NotAllSame\", \"AllSame\"]:\n",
    "                comps = d_comp[ds]\n",
    "                prefix = d_conv[ds + \"_\" + ct]\n",
    "                print(ds + \"_\" + ct)\n",
    "                folder = \"Pritchard\"\n",
    "                file = prefix + \"_\" + ags + \"_DownCounts1-100_General_\" + cont + folder + \".txt\"\n",
    "                v = pd.read_csv(folder + \"/\" + file, sep = \"\\t\")\n",
    "                for ct_filter in [\"All\", \"Exc\", \"Inh\"]:\n",
    "                    for cell_num in cells:\n",
    "                        for log_strat in log:\n",
    "                            for filt_strat in filt_strats:\n",
    "                                for cpm_filt_strat in filt_cpm:\n",
    "                                    for comp in comps:\n",
    "                                        for dist_met in [\"Euclidean\", \"L1\"]:\n",
    "                                            if \"Not\" not in cont:\n",
    "                                                types = [\"Med High\", \"Med Med\", \"Low High\", \"Low Low\", \"NoFilt Low Size\", \"NoFilt Med Size\"]\n",
    "                                            else:\n",
    "                                                types = [\"High\", \"Med\", \"Low\", \"No Filt Matched Size\"]\n",
    "                                            for keep_this_t in types:\n",
    "                                                mr, mp = just_corr2(v, folder, file, ct_filter, comp, log=log_strat, fcpm=cpm_filt_strat, rf=filt_strat, ncells = cell_num, ags = ags, dist_met = dist_met, keep_this = keep_this_t)\n",
    "                                                #print([ct, ds, ct_filter, comp, cell_num, log_strat, filt_strat, cpm_filt_strat, ags, dist_met, cont, keep_this_t, mr, mp])\n",
    "                                                out.append([ct, ds, ct_filter, comp, cell_num, log_strat, filt_strat, cpm_filt_strat, ags, dist_met, cont_write, keep_this_t, mr, mp])\n",
    "df = pd.DataFrame(out)\n",
    "df.columns = [\"Clustering resolution\", \"Dataset\", \"Class\", \"Comparison\", \"Number of cells\", \"Log transform\", \"Raw count cutoff\", \"CPM cutoff\", \"All genes same?\", \"Distance metric to compare expression\", \"Control for expression level?\", \"Evolutionary constraint level bin\", \"Median Spearman's rho\", \"Median Spearman's p-value\"]\n",
    "df.to_csv(\"Supplemental_Table4.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3617ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### To make supplemental table 4 ###\n",
    "\n",
    "out = []\n",
    "d_conv = {\"Sestan_DLPFC_subtype\":\"Sestan_DLPFC_subtype\", \"Sestan_DLPFC_subclass\":\"Sestan_DLPFC_subclass\", \"Allen_MTG_subclass\":\"Allen_MTG_subclass\", \"Allen_M1_subtype\":\"Allen_M1_cross_species_cluster_label\", \"Allen_M1_subclass\":\"Allen_M1_subclass_label\", \"Allen_MTG_subtype\":\"Allen_MTG_cross_species_cluster\"}\n",
    "d_comp = {\"Allen_M1\":[\"Human-Marmoset\", \"Human-Mouse\", \"Mouse-Marmoset\"], \"Sestan_DLPFC\":[\"Human-Marmoset\", \"Human-Rhesus\", \"Human-Chimpanzee\", \"Rhesus-Chimpanzee\", \"Rhesus-Marmoset\", \"Chimpanzee-Marmoset\"], \\\n",
    "         \"Allen_MTG\":[\"Human-Marmoset\", \"Human-Rhesus\", \"Human-Gorilla\", \"Human-Chimp\", \"Rhesus-Gorilla\", \"Rhesus-Chimp\", \"Rhesus-Marmoset\", \"Gorilla-Chimp\", \"Gorilla-Marmoset\", \"Chimp-Marmoset\"]}\n",
    "\n",
    "cells = [500, 50, 100, 250]\n",
    "log = [\"Log2\"]\n",
    "filt_strats = [10 ,25]\n",
    "filt_cpm = [1, 5]\n",
    "\n",
    "for cont in [\"ContExp_\", \"NotContExp_\"]:\n",
    "    if \"Not\" not in cont:\n",
    "        cont_write = \"Yes\"\n",
    "    else:\n",
    "        cont_write = \"No\"\n",
    "    for ds in [\"Allen_MTG\", \"Allen_M1\", \"Sestan_DLPFC\"]:\n",
    "        for ct in [\"subclass\", \"subtype\"]:\n",
    "            for ags in [\"NotAllSame\", \"AllSame\"]:\n",
    "                comps = d_comp[ds]\n",
    "                prefix = d_conv[ds + \"_\" + ct]\n",
    "                print(ds + \"_\" + ct)\n",
    "                folder = \"Tau\"\n",
    "                file = prefix + \"_\" + ags + \"_DownCounts1-100_General_\" + cont + folder + \".txt\"\n",
    "                v = pd.read_csv(folder + \"/\" + file, sep = \"\\t\")\n",
    "                for ct_filter in [\"All\", \"Exc\", \"Inh\"]:\n",
    "                    for cell_num in cells:\n",
    "                        for log_strat in log:\n",
    "                            for filt_strat in filt_strats:\n",
    "                                for cpm_filt_strat in filt_cpm:\n",
    "                                    for comp in comps:\n",
    "                                        for dist_met in [\"Euclidean\", \"L1\"]:\n",
    "                                            if \"Not\" not in cont:\n",
    "                                                types = [\"Med High\", \"Med Med\", \"Low High\", \"Low Low\", \"NoFilt Low Size\", \"NoFilt Med Size\"]\n",
    "                                            else:\n",
    "                                                types = [\"High\", \"Med\", \"Low\", \"No Filt Matched Size\"]\n",
    "                                            for keep_this_t in types:\n",
    "                                                mr, mp = just_corr2(v, folder, file, ct_filter, comp, log=log_strat, fcpm=cpm_filt_strat, rf=filt_strat, ncells = cell_num, ags = ags, dist_met = dist_met, keep_this = keep_this_t)\n",
    "                                                #print([ct, ds, ct_filter, comp, cell_num, log_strat, filt_strat, cpm_filt_strat, ags, dist_met, cont, keep_this_t, mr, mp])\n",
    "                                                out.append([ct, ds, ct_filter, comp, cell_num, log_strat, filt_strat, cpm_filt_strat, ags, dist_met, cont_write, keep_this_t, mr, mp])\n",
    "df = pd.DataFrame(out)\n",
    "df.columns = [\"Clustering resolution\", \"Dataset\", \"Class\", \"Comparison\", \"Number of cells\", \"Log transform\", \"Raw count cutoff\", \"CPM cutoff\", \"All genes same?\", \"Distance metric to compare expression\", \"Control for expression level?\", \"Tau bin\", \"Median Spearman's rho\", \"Median Spearman's p-value\"]\n",
    "df.to_csv(\"Supplemental_Table3.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89759c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to make regression plot comparing cell type proportion and divergence ###\n",
    "### For reasons unknown, you must redefine the function for every run to get the tick marks to appear properly ###\n",
    "#Set parameters for the plot\n",
    "plt.rcParams['xtick.major.size'] = 10\n",
    "plt.rcParams['xtick.major.width'] = 1.5\n",
    "plt.rcParams['xtick.minor.size'] = 4\n",
    "plt.rcParams['xtick.minor.width'] = 1\n",
    "plt.rcParams['xtick.bottom'] = True\n",
    "plt.rcParams['ytick.left'] = True\n",
    "\n",
    "def ctp_regplot(folder, file, ctf, scomp, log=\"Log2\", fcpm=1, rf=25, ncells=250, ags=\"NotAllSame\", dc=\"DownCounts\", keep_this = \"\", rel_to = \"\", dist_met = \"Spearman\"):\n",
    "    \n",
    "    #Read in file and filter down to only the parameters of interest\n",
    "    v = pd.read_csv(folder + \"/\" + file, sep = \"\\t\")\n",
    "    v = v[(v[\"Log\"].isin([log])) & (v[\"CPM filtering\"].isin([fcpm])) & (v[\"Raw filtering\"].isin([rf])) & (v[\"Number cells\"].isin([ncells])) & (v[\"All genes same?\"]).isin([ags]) & (v[\"Downsample counts?\"].isin([dc]))]\n",
    "    v = v[(v[\"Cell type filtering\"].isin([ctf])) & (v[\"Comparison\"].isin([scomp]))]\n",
    "    if folder == \"Tau\" or folder == \"ExprLevel\":\n",
    "        if \"NotContExp\" in file or folder == \"ExprLevel\" or \"ContExp\" in file:\n",
    "            v = v[v[folder].isin([keep_this])]\n",
    "    \n",
    "    #Compute median rho and median p-value\n",
    "    median_rho = np.median(v[\"Spearman correlation dist_met_\" + dist_met.lower()])\n",
    "    median_p = np.median(v[\"Spearman correlation p-value dist_met_\" + dist_met.lower()])\n",
    "\n",
    "    #If the median value exists, pull the lowest iteration number with the median value\n",
    "    #If the median value does not exist, pull the closest value breaking ties by consistently showing the modal correlation within that\n",
    "    #If that is still a tie, just show the one with the lowest number\n",
    "    x = []\n",
    "    for i in list(v[\"Spearman correlation dist_met_\" + dist_met.lower()]):\n",
    "        x.append(i-median_rho)\n",
    "    if 0 in x:\n",
    "        keep_iter = list(v[v[\"Spearman correlation dist_met_\" + dist_met.lower()].isin([median_rho])][\"Iteration\"])[0]\n",
    "    else:\n",
    "        pos = 0\n",
    "        neg = 0\n",
    "        first = 0\n",
    "        check_first = 1\n",
    "        first_pos = 0\n",
    "        first_neg = 0\n",
    "        check_first_pos = 1\n",
    "        check_first_neg = 1\n",
    "        for i in range(len(x)):\n",
    "            if np.abs(x[i]) == min(np.abs(x)):\n",
    "                if check_first:\n",
    "                    first = i + 1\n",
    "                    check_first = 0\n",
    "                if x[i] > 0:\n",
    "                    pos += 1\n",
    "                    if check_first_pos:\n",
    "                        first_pos = i + 1\n",
    "                        check_first_pos = 0\n",
    "                elif x[i] < 0:\n",
    "                    neg += 1\n",
    "                    if check_first_neg:\n",
    "                        first_neg = i + 1\n",
    "                        check_first_neg = 0\n",
    "        if pos > neg:\n",
    "            keep_iter = first_pos\n",
    "        elif pos < neg:\n",
    "            keep_iter = first_neg\n",
    "        else:\n",
    "            keep_iter = first\n",
    "    print(\"Iteration shown is: \" + str(keep_iter))\n",
    "    \n",
    "    #Read in the distance matrix and do some computation\n",
    "    v = pd.read_csv(folder + \"/\" + file.replace(\".txt\", \"_distances.txt\"), sep = \"\\t\")\n",
    "    v = v[(v[\"Log\"].isin([log])) & (v[\"CPM filtering\"].isin([fcpm])) & (v[\"Raw filtering\"].isin([rf])) & (v[\"Number cells\"].isin([ncells])) & (v[\"All genes same?\"]).isin([ags]) & (v[\"Downsample counts?\"].isin([dc]))]\n",
    "    v = v[(v[\"Comparison\"].isin([scomp])) & (v[\"Iteration\"].isin([keep_iter]))]\n",
    "    \n",
    "    if folder == \"Tau\" or folder == \"ExprLevel\":\n",
    "        if \"NotContExp\" in file or folder == \"ExprLevel\" or \"ContExp\" in file:\n",
    "            v = v[v[folder].isin([keep_this])]\n",
    "            v = v.head(int(v.shape[0]/2))\n",
    "            \n",
    "    #Get which cell types to keep\n",
    "    keep_cts = get_ct_keep(\"_\".join(file.split(\"_\")[0:2]), file.split(\"_\")[2], ctf)\n",
    "    \n",
    "    #Read in cell type numbers to compute cell type proportions\n",
    "    ctn = pd.read_csv(\"CellTypeNumbers/\" + file.split(\"_\" + ags)[0] + \"_CellTypeNumbers.txt\", sep = \"\\t\").set_index(\"Cell type\")\n",
    "    ctn = ctn.loc[keep_cts]\n",
    "    for spec in scomp.split(\"-\"):\n",
    "        ctn[\"Proportion \" + spec] = ctn[\"Count \" + spec]/np.sum(ctn[\"Count \" + spec])\n",
    "    ctn[\"Cell type proportion\"] = (ctn[\"Proportion \" + scomp.split(\"-\")[0]] + ctn[\"Proportion \" + scomp.split(\"-\")[1]])/2\n",
    "    for i in list(ctn.columns):\n",
    "        if \"Count\" in i:\n",
    "            ctn = ctn[ctn[i] >= ncells]\n",
    "        \n",
    "    keep_cts = np.intersect1d(keep_cts, ctn.index)\n",
    "    v = v[v[\"Cell type\"].isin(keep_cts)].set_index(\"Cell type\")\n",
    "    \n",
    "    ctn = ctn.loc[keep_cts]\n",
    "    v = v.join(ctn)\n",
    "    \n",
    "    v[\"Log cell type proportion\"] = np.log10(v[\"Cell type proportion\"])\n",
    "    fig, ax = plt.subplots(figsize = (7, 5))\n",
    "    sns.set(font_scale = 1.6)\n",
    "    sns.set_style(\"white\")\n",
    "    \n",
    "    print(spearmanr(v[\"Cell type proportion\"], v[\"Distance \" + dist_met.lower()]))\n",
    "    ax = sns.regplot(data = v, x = \"Log cell type proportion\", y = \"Distance \" + dist_met.lower(), color = palette[ctf], marker = shapes[\"_\".join(file.split(\"_\")[0:2])], scatter_kws = {\"edgecolors\":\"black\"})\n",
    "    ticks = ax.get_xticks()\n",
    "\n",
    "    #Manually specific the tick locations for each use case\n",
    "    if \"subclass\" in file:\n",
    "        if \"All\" == ctf:\n",
    "            ticks = [-2, -1.5, -1, -0.5]\n",
    "            major_ticks2 = [0.01, 0.1]\n",
    "            major_ticks = [np.log10(x) for x in major_ticks2]\n",
    "            minor_ticks2 = [0.007, 0.008, 0.009, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.2, 0.3]\n",
    "            if \"Allen_M1\" in file:\n",
    "                minor_ticks2 = [0.009, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.2, 0.3]\n",
    "            minor_ticks = [np.log10(x) for x in minor_ticks2]\n",
    "            minor_ticks2 = ['' for x in minor_ticks2]\n",
    "        elif \"Inh\" == ctf or \"Exc\" == ctf:\n",
    "            ticks = [-1.5, -1, -0.5]\n",
    "            major_ticks2 = [0.03, 0.1, 0.3]\n",
    "            major_ticks = [np.log10(x) for x in major_ticks2]\n",
    "            minor_ticks2 = [0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.2, 0.3]\n",
    "            if \"Sestan_DLPFC\" in file:\n",
    "                if \"Exc\" == ctf:\n",
    "                    major_ticks2 = [0.01, 0.1, 0.3]\n",
    "                    major_ticks = [np.log10(x) for x in major_ticks2]\n",
    "                    minor_ticks2 = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.2, 0.3]\n",
    "                else:\n",
    "                    major_ticks2 = [0.03, 0.1, 0.3]\n",
    "                    major_ticks = [np.log10(x) for x in major_ticks2]\n",
    "                    minor_ticks2 = [0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.2, 0.3]\n",
    "            elif \"Allen_M1\" in file:\n",
    "                minor_ticks2 = [0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.2, 0.3]\n",
    "                if \"Inh\" == ctf:\n",
    "                    major_ticks2 = [0.05, 0.1, 0.3]\n",
    "                    major_ticks = [np.log10(x) for x in major_ticks2]\n",
    "                    minor_ticks2 = [0.05, 0.06, 0.07, 0.08, 0.09, 0.2, 0.3]\n",
    "            minor_ticks = [np.log10(x) for x in minor_ticks2]\n",
    "            minor_ticks2 = ['' for x in minor_ticks2]\n",
    "    elif \"subtype\" in file or \"cross_species_cluster\" in file:\n",
    "        if ctf == \"All\":\n",
    "            ticks = [-3, -2.5, -2, -1.5, -1]\n",
    "            major_ticks2 = [0.001, 0.01, 0.1]\n",
    "            major_ticks = [np.log10(x) for x in major_ticks2]\n",
    "            minor_ticks2 = [0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.2]\n",
    "            minor_ticks = [np.log10(x) for x in minor_ticks2]\n",
    "            minor_ticks2 = ['' for x in minor_ticks2]\n",
    "        elif ctf == \"Exc\":\n",
    "            ticks = [-2.5, -2, -1.5, -1, -0.5]\n",
    "            major_ticks2 = [0.002, 0.01, 0.1]\n",
    "            major_ticks = [np.log10(x) for x in major_ticks2]\n",
    "            minor_ticks2 = [0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.2]\n",
    "            minor_ticks = [np.log10(x) for x in minor_ticks2]\n",
    "            minor_ticks2 = ['' for x in minor_ticks2]\n",
    "            print(minor_ticks)\n",
    "        elif ctf == \"Inh\":\n",
    "            ticks = [-2.5, -2, -1.5, -1, -0.5]\n",
    "            major_ticks2 = [0.01, 0.1]\n",
    "            major_ticks = [np.log10(x) for x in major_ticks2]\n",
    "            minor_ticks2 = [0.005, 0.006, 0.007, 0.008, 0.009, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.2]\n",
    "            minor_ticks = [np.log10(x) for x in minor_ticks2]\n",
    "            minor_ticks2 = ['' for x in minor_ticks2]\n",
    "            if \"Sestan\" in file:\n",
    "                major_ticks2 = [0.003, 0.01, 0.08]\n",
    "                major_ticks = [np.log10(x) for x in major_ticks2]\n",
    "                minor_ticks2 = [0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08]\n",
    "                minor_ticks = [np.log10(x) for x in minor_ticks2]\n",
    "                minor_ticks2 = ['' for x in minor_ticks2]\n",
    "                ticks = [-2.5, -2, -1.5, -1]\n",
    "                if ncells == 500:\n",
    "                    major_ticks2 = [0.02, 0.08]\n",
    "                    major_ticks = [np.log10(x) for x in major_ticks2]\n",
    "                    minor_ticks2 = [0.02, 0.04, 0.05, 0.06, 0.07, 0.08]\n",
    "                    minor_ticks = [np.log10(x) for x in minor_ticks2]\n",
    "                    minor_ticks2 = ['' for x in minor_ticks2]\n",
    "                    ticks = [-2.5, -2, -1.5, -1]\n",
    "    \n",
    "    ax.set_xticks(major_ticks, major_ticks2, minor = False)\n",
    "    ax.set_xticks(minor_ticks, minor_ticks2, minor = True)\n",
    "\n",
    "    #Add lables and titles appropriately\n",
    "    plt.xlabel(\"Cell type proportion\")\n",
    "    if dist_met == \"Euclidean\" or dist_met == \"L1\":\n",
    "        plt.ylabel(dist_met + \" distance\")\n",
    "    else:\n",
    "        plt.ylabel(dist_met + \" correlation distance\")\n",
    "    plt.title(scomp.split(\"-\")[0].replace(\"anzee\", \"\") + \"-\" + scomp.split(\"-\")[1].lower().replace(\"anzee\", \"\") + \" divergence vs. cell type prop.\")\n",
    "    if folder == \"ExprLevel\":\n",
    "        if \"ContTau\" not in file:\n",
    "            plt.title(keep_this + \"ly expressed genes\")\n",
    "        else:\n",
    "            plt.title(keep_this.split(\" \")[1] + \"ly expressed genes,\\ncontrolling for cell type-specificity\")\n",
    "    elif folder == \"Tau\":\n",
    "        if \"NotContExp\" in file:\n",
    "            if \"High\" in keep_this:\n",
    "                plt.title(\"High cell type-specificity of expression\")\n",
    "            elif \"Low\" in keep_this:\n",
    "                plt.title(\"Low cell type-specificity of expression\")\n",
    "        else:\n",
    "            if \"High\" in keep_this:\n",
    "                plt.title(\"High cell type-specificity of expression,\\ncontrolling for expression level\")\n",
    "            elif \"Low\" in keep_this:\n",
    "                plt.title(\"Low cell type-specificity of expression,\\ncontrolling for expression level\")\n",
    "            \n",
    "    plt.show()\n",
    "    \n",
    "    #Return the median rho, median p-value, and averaged table\n",
    "    return median_rho, median_p, v\n",
    "\n",
    "mr, mp, vhg = ctp_regplot(\"Tau\", \"Allen_MTG_subclass_NotAllSame_DownCounts1-100_General_NotContExp_Tau.txt\", \"All\", \"Human-Marmoset\", ncells = 250, ags = \"NotAllSame\", dist_met = \"Euclidean\", keep_this = \"High\")\n",
    "print(mr, mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9423639",
   "metadata": {},
   "outputs": [],
   "source": [
    "vhg = vhg.sort_values(\"Proportion Human\", ascending = False)\n",
    "order = vhg.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b25d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used to create the cell type divergence for figure 1, reran for each species combination\n",
    "fig, ax = plt.subplots(figsize = (3, 1))\n",
    "sns.barplot(data = vhg, y = \"Distance spearman\", x = \"Cell type\", color = new_palette[\"Marmoset\"], order = order)\n",
    "plt.xlabel(None)\n",
    "plt.ylabel(None)\n",
    "plt.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False)\n",
    "plt.tick_params(\n",
    "    axis='y',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    left=False,      # ticks along the bottom edge are off\n",
    "    right=False,         # ticks along the top edge are off\n",
    "    labelleft=False)\n",
    "plt.ylim(np.min(vhg[\"Distance spearman\"]) - 0.05*np.min(vhg[\"Distance spearman\"]), np.max(vhg[\"Distance spearman\"]) + 0.05*np.max(vhg[\"Distance spearman\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbf5950",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The same as the above but for cell type proportions in  M1\n",
    "new_palette = {\"Human\":\"#FF2C0C\", \"Chimp\":\"#0058FF\", \"Rhesus\":\"#AD6D3E\", \"Marmoset\":\"#551A7F\", \"Gorilla\":\"#5C687D\", \"Mouse\":\"#C43E96\"}\n",
    "vhg = vhg.sort_values(\"Proportion Human\", ascending = False)\n",
    "vhg[\"Proportion Mouse\"] = vhg[\"Count Mouse\"]/np.sum(vhg[\"Count Mouse\"])\n",
    "vhg[\"Prop Human\"] = np.log10(1 + 100*vhg[\"Proportion Human\"])\n",
    "vhg[\"Prop Mouse\"] = np.log10(1 + 100*vhg[\"Proportion Mouse\"])\n",
    "vhg[\"Prop Marmoset\"] = np.log10(1 + 100*vhg[\"Proportion Marmoset\"])\n",
    "\n",
    "#vhg[\"Prop Human\"] = np.log10(vhg[\"Proportion Human\"]) - np.min(np.log10(vhg[\"Proportion Human\"])) + 0.3\n",
    "fig, ax = plt.subplots(figsize = (3, 1))\n",
    "sns.barplot(data = vhg, y = \"Prop Human\", x = \"Cell type\", color = new_palette[\"Human\"], order = order)\n",
    "#plt.ylim(0, 0.4)\n",
    "plt.xlabel(None)\n",
    "plt.ylabel(None)\n",
    "plt.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False)\n",
    "plt.tick_params(\n",
    "    axis='y',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    left=False,      # ticks along the bottom edge are off\n",
    "    right=False,         # ticks along the top edge are off\n",
    "    labelleft=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e472567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Sestan_DLPFC\n",
    "\n",
    "new_palette = {\"Human\":\"#FF2C0C\", \"Chimp\":\"#0058FF\", \"Rhesus\":\"#AD6D3E\", \"Marmoset\":\"#551A7F\", \"Gorilla\":\"#5C687D\", \"Mouse\":\"#C43E96\"}\n",
    "vhg = vhg.sort_values(\"Proportion Human\", ascending = False)\n",
    "vhg[\"Proportion Chimp\"] = vhg[\"Count Chimpanzee\"]/np.sum(vhg[\"Count Chimpanzee\"])\n",
    "vhg[\"Proportion Rhesus\"] = vhg[\"Count Rhesus\"]/np.sum(vhg[\"Count Rhesus\"])\n",
    "vhg[\"Prop Human\"] = np.log10(1 + 100*vhg[\"Proportion Human\"])\n",
    "vhg[\"Prop Chimp\"] = np.log10(1 + 100*vhg[\"Proportion Chimp\"])\n",
    "vhg[\"Prop Rhesus\"] = np.log10(1 + 100*vhg[\"Proportion Rhesus\"])\n",
    "vhg[\"Prop Marmoset\"] = np.log10(1 + 100*vhg[\"Proportion Marmoset\"])\n",
    "\n",
    "#vhg[\"Prop Human\"] = np.log10(vhg[\"Proportion Human\"]) - np.min(np.log10(vhg[\"Proportion Human\"])) + 0.3\n",
    "fig, ax = plt.subplots(figsize = (3, 1))\n",
    "sns.barplot(data = vhg, y = \"Prop Human\", x = \"Cell type\", color = new_palette[\"Human\"], order = order)\n",
    "#plt.ylim(0, 0.4)\n",
    "plt.xlabel(None)\n",
    "plt.ylabel(None)\n",
    "plt.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False)\n",
    "plt.tick_params(\n",
    "    axis='y',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    left=False,      # ticks along the bottom edge are off\n",
    "    right=False,         # ticks along the top edge are off\n",
    "    labelleft=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00006c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For MTG\n",
    "\n",
    "new_palette = {\"Human\":\"#FF2C0C\", \"Chimp\":\"#0058FF\", \"Rhesus\":\"#AD6D3E\", \"Marmoset\":\"#551A7F\", \"Gorilla\":\"#5C687D\"}\n",
    "vhg = vhg.sort_values(\"Proportion Human\", ascending = False)\n",
    "vhg[\"Proportion Chimp\"] = vhg[\"Count Chimp\"]/np.sum(vhg[\"Count Chimp\"])\n",
    "vhg[\"Proportion Gorilla\"] = vhg[\"Count Gorilla\"]/np.sum(vhg[\"Count Gorilla\"])\n",
    "vhg[\"Proportion Rhesus\"] = vhg[\"Count Rhesus\"]/np.sum(vhg[\"Count Rhesus\"])\n",
    "vhg[\"Prop Human\"] = np.log10(1 + 100*vhg[\"Proportion Human\"])\n",
    "vhg[\"Prop Chimp\"] = np.log10(1 + 100*vhg[\"Proportion Chimp\"])\n",
    "vhg[\"Prop Gorilla\"] = np.log10(1 + 100*vhg[\"Proportion Gorilla\"])\n",
    "vhg[\"Prop Rhesus\"] = np.log10(1 + 100*vhg[\"Proportion Rhesus\"])\n",
    "vhg[\"Prop Marmoset\"] = np.log10(1 + 100*vhg[\"Proportion Marmoset\"])\n",
    "\n",
    "#vhg[\"Prop Human\"] = np.log10(vhg[\"Proportion Human\"]) - np.min(np.log10(vhg[\"Proportion Human\"])) + 0.3\n",
    "fig, ax = plt.subplots(figsize = (3, 1))\n",
    "sns.barplot(data = vhg, y = \"Prop Rhesus\", x = \"Cell type\", color = new_palette[\"Rhesus\"], order = order)\n",
    "#plt.ylim(0, 0.4)\n",
    "plt.xlabel(None)\n",
    "plt.ylabel(None)\n",
    "plt.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False)\n",
    "plt.tick_params(\n",
    "    axis='y',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    left=False,      # ticks along the bottom edge are off\n",
    "    right=False,         # ticks along the top edge are off\n",
    "    labelleft=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180f1618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to color patches (the bars) in the barplot\n",
    "def color_patches(t_ax, folder, dfp, comps, col_name, cont_exp = False, skip_sm = True, lm = \"Low\", symbol = \"*\", name = \"Median p-value\", name2 = \"Median rho\"):\n",
    "    fontsize = 35\n",
    "    patches = t_ax.patches\n",
    "    if folder == \"Vanilla\":\n",
    "        for i in range(len(patches) - 3):\n",
    "            patch = patches[i]\n",
    "            if i < len(comps):\n",
    "                cur = \"All\"\n",
    "            elif i < 2*len(comps):\n",
    "                cur = \"Excitatory\"\n",
    "            else:\n",
    "                cur = \"Inhibitory\"\n",
    "            row = dfp[(dfp[col_name].isin([cur])) & (dfp[\"Comparison\"].isin([comps[i%len(comps)]]))]\n",
    "            if float(row[name]) < 0.05 and float(row[name2]) < 0:\n",
    "                plt.text(patch.get_x() + patch.get_width()/2, 0, symbol, ha='center', size = fontsize)\n",
    "            patch.set_edgecolor(palette[cur])\n",
    "            patch.set_facecolor(palette[cur] + \"1A\")\n",
    "    elif (folder == \"ExprLevel\" and not cont_exp) or not cont_exp:\n",
    "        if skip_sm:\n",
    "            for i in range(len(patches) - 3):\n",
    "                patch = patches[i]\n",
    "                if i < len(comps):\n",
    "                    cur = \"High\"\n",
    "                elif i < 2*len(comps):\n",
    "                    cur = \"Med\"\n",
    "                else:\n",
    "                    cur = \"Low\"\n",
    "                row = dfp[(dfp[col_name].isin([cur])) & (dfp[\"Comparison\"].isin([comps[i%len(comps)]]))]\n",
    "                if float(row[name]) < 0.05 and float(row[name2]) < 0:\n",
    "                    plt.text(patch.get_x() + patch.get_width()/2, 0, symbol, ha='center', size = fontsize)\n",
    "                patch.set_edgecolor(palette_strat[cur])\n",
    "                patch.set_facecolor(palette_strat[cur] + \"1A\")\n",
    "        else:\n",
    "            for i in range(len(patches) - 4):\n",
    "                patch = patches[i]\n",
    "                if i < len(comps):\n",
    "                    cur = \"High\"\n",
    "                elif i < 2*len(comps):\n",
    "                    cur = \"Med\"\n",
    "                elif i < 3*len(comps):\n",
    "                    cur = \"Low\"\n",
    "                else:\n",
    "                    cur = \"No Filt Matched Size\"\n",
    "                row = dfp[(dfp[\"Expression level\"].isin([cur])) & (dfp[\"Comparison\"].isin([comps[i%len(comps)]]))]\n",
    "                if float(row[name]) < 0.05 and float(row[name2]) < 0:\n",
    "                    plt.text(patch.get_x() + patch.get_width()/2, 0, symbol, ha='center', size = fontsize)\n",
    "                patch.set_edgecolor(palette_strat[cur])\n",
    "                patch.set_facecolor(palette_strat[cur] + \"1A\")\n",
    "    elif cont_exp:\n",
    "        if skip_sm:\n",
    "            for i in range(len(patches) - 2):\n",
    "                patch = patches[i]\n",
    "                if i < len(comps):\n",
    "                    cur = lm + \" High\"\n",
    "                else:\n",
    "                    cur = lm + \" \" + lm\n",
    "                row = dfp[(dfp[col_name].isin([cur])) & (dfp[\"Comparison\"].isin([comps[i%len(comps)]]))]\n",
    "                if float(row[name]) < 0.05 and float(row[name2]) < 0:\n",
    "                    plt.text(patch.get_x() + patch.get_width()/2, 0, symbol, ha='center', size = fontsize)\n",
    "                patch.set_edgecolor(palette_strat_cont[cur])\n",
    "                patch.set_facecolor(palette_strat_cont[cur] + \"1A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d25cdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to compute statistics to compare spearman correlation coefficients\n",
    "def compute_stats(comps, iterer, col_name, dfp_stats, cont_exp = False):\n",
    "    out = []\n",
    "    if not cont_exp:\n",
    "        for i in comps:\n",
    "            for j in iterer:\n",
    "                velse = dfp_stats[(dfp_stats[\"Comparison\"].isin([i])) & (dfp_stats[col_name].isin([j]))]\n",
    "                if j == \"High\":\n",
    "                    out.append([str(i), j, float(velse[\"Median rho\"]), float(velse[\"Median p-value\"]), 0, 1])\n",
    "                else:\n",
    "                    vhigh = dfp_stats[(dfp_stats[\"Comparison\"].isin([i])) & (dfp_stats[col_name].isin([\"High\"]))]\n",
    "                    corr_test = independent_corr(float(vhigh[\"Median rho\"]), float(velse[\"Median rho\"]), int(vhigh[\"Number cell types\"]), int(velse[\"Number cell types\"]), method='fisher')\n",
    "                    out.append([str(i), j, float(velse[\"Median rho\"]), float(velse[\"Median p-value\"]), corr_test[0], corr_test[1]])\n",
    "    else:\n",
    "        for i in comps:\n",
    "            for j in iterer:\n",
    "                velse = dfp_stats[(dfp_stats[\"Comparison\"].isin([i])) & (dfp_stats[col_name].isin([j]))]\n",
    "                if \"High\" in j:\n",
    "                    out.append([str(i), j, float(velse[\"Median rho\"]), float(velse[\"Median p-value\"]), 0, 1])\n",
    "                else:\n",
    "                    if \"Med\" in j:\n",
    "                        vhigh = dfp_stats[(dfp_stats[\"Comparison\"].isin([i])) & (dfp_stats[col_name].isin([\"Med High\"]))]\n",
    "                        corr_test = independent_corr(float(vhigh[\"Median rho\"]), float(velse[\"Median rho\"]), int(vhigh[\"Number cell types\"]), int(velse[\"Number cell types\"]), method='fisher')\n",
    "                        out.append([str(i), j, float(velse[\"Median rho\"]), float(velse[\"Median p-value\"]), corr_test[0], corr_test[1]])\n",
    "                    elif \"Low\" in j:\n",
    "                        vhigh = dfp_stats[(dfp_stats[\"Comparison\"].isin([i])) & (dfp_stats[col_name].isin([\"Low High\"]))]\n",
    "                        corr_test = independent_corr(float(vhigh[\"Median rho\"]), float(velse[\"Median rho\"]), int(vhigh[\"Number cell types\"]), int(velse[\"Number cell types\"]), method='fisher')\n",
    "                        out.append([str(i), j, float(velse[\"Median rho\"]), float(velse[\"Median p-value\"]), corr_test[0], corr_test[1]])\n",
    "        \n",
    "    dfp2 = pd.DataFrame(out)\n",
    "    dfp2.columns = [\"Comparison\", col_name, \"Median rho\", \"Median p-value\", \"Comp high z-score\", \"Comp high p-value\"]\n",
    "    return dfp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb1a686",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to make the swarmplot + barplot to show median and data across all iterations\n",
    "\n",
    "def ctp_swarmplot(folder, file, ctf, show_lm = \"Low\", skip_sm = True, log=\"Log2\", fcpm=1, rf=25, ncells=250, ags=\"NotAllSame\", dc=\"DownCounts\", dist_met = \"Spearman\"):\n",
    "    dist = \"Spearman correlation dist_met_\" + dist_met.lower()\n",
    "    #Read in the file\n",
    "    v = pd.read_csv(folder + \"/\" + file, sep = \"\\t\")\n",
    "    \n",
    "    print(\"Maximum iteration reached: \" + str(np.max(v[\"Iteration\"])))\n",
    "    v = v[(v[\"Log\"].isin([log])) & (v[\"CPM filtering\"].isin([fcpm])) & (v[\"Raw filtering\"].isin([rf])) & (v[\"Number cells\"].isin([ncells])) & (v[\"All genes same?\"]).isin([ags]) & (v[\"Downsample counts?\"].isin([dc]))]\n",
    "    v[\"Comparison\"] = [x.split(\"-\")[0] + \"-\" + x.split(\"-\")[1].lower() for x in list(v[\"Comparison\"])]\n",
    "\n",
    "    #Unless it is vanilla, filter cell types\n",
    "    if \"ExprLevel\" == folder or \"Tau\" == folder or \"Pritchard\" == folder:\n",
    "        v = v[v[\"Cell type filtering\"].isin([ctf])]\n",
    "    \n",
    "    #Replace names and set parameters based on which dataset and folder are used\n",
    "    v[\"Cell type filtering\"] = v[\"Cell type filtering\"].replace(\"Exc\", \"Excitatory\").replace(\"Inh\", \"Inhibitory\")\n",
    "    out = []\n",
    "    if \"Allen_M1\" in file:\n",
    "        comps = [\"Human-marmoset\", \"Human-mouse\", \"Mouse-marmoset\"]\n",
    "    elif \"Allen_MTG\" in file:\n",
    "        comps = [\"Human-marmoset\", \"Human-rhesus\", \"Human-gorilla\", \"Human-chimp\", \"Rhesus-marmoset\", \"Rhesus-gorilla\", \"Rhesus-chimp\", \"Gorilla-marmoset\", \"Gorilla-chimp\", \"Chimp-marmoset\"]\n",
    "    elif \"Sestan_DLPFC\" in file:\n",
    "        v[\"Comparison\"] = v[\"Comparison\"].replace(\"Human-chimpanzee\", \"Human-chimp\").replace(\"Rhesus-chimpanzee\", \"Rhesus-chimp\").replace(\"Chimpanzee-marmoset\", \"Chimp-marmoset\")\n",
    "        comps = [\"Human-marmoset\", \"Human-rhesus\", \"Human-chimp\", \"Rhesus-marmoset\", \"Rhesus-chimp\", \"Chimp-marmoset\"]\n",
    "    \n",
    "    #Set some more parameters\n",
    "    if folder == \"Vanilla\":\n",
    "        iterer = [\"All\", \"Excitatory\", \"Inhibitory\"]\n",
    "        old_col_name = \"Cell type filtering\"\n",
    "        col_name = \"Neuron type\"\n",
    "    else:\n",
    "        old_col_name = folder\n",
    "        if folder == \"ExprLevel\":\n",
    "            col_name = \"Expression level\"\n",
    "        elif folder == \"Tau\":\n",
    "            col_name = \"Tau\"\n",
    "        elif folder == \"Pritchard\":\n",
    "            col_name = \"Constraint\"\n",
    "        \n",
    "        if (folder == \"ExprLevel\" and \"ContTau\" not in file) or \"NotContExp\" in file:\n",
    "            iterer = [\"High\", \"Med\", \"Low\", \"No Filt Matched Size\"]\n",
    "            old_col_name = folder\n",
    "        else:\n",
    "            iterer = ['Low High', 'Low Low', 'NoFilt Low Size', 'Med High', 'Med Med', 'NoFilt Med Size']\n",
    "            iterer_d = {}\n",
    "            for i in range(len(iterer)):\n",
    "                iterer_d[iterer[i]] = i\n",
    "    \n",
    "    #Iterate through computing median p-value and median rho\n",
    "    for i in comps:\n",
    "        for j in iterer:\n",
    "            vv = v[(v[\"Comparison\"].isin([i])) & (v[old_col_name].isin([j]))]\n",
    "            out.append([str(i), j, np.median(vv[dist]), np.median(vv[dist.replace(\"correlation\", \"correlation p-value\")]), int(vv.iloc[0][\"Number cell types\"].split(\", \")[0].replace(\"(\", \"\"))])\n",
    "    dfp = pd.DataFrame(out)\n",
    "    dfp.columns = [\"Comparison\", col_name, \"Median rho\", \"Median p-value\", \"Number cell types\"]\n",
    "    v_stats = v.copy()\n",
    "    dfp_stats = dfp.copy()\n",
    "    \n",
    "    #Create plots\n",
    "    if \"Vanilla\" == folder:\n",
    "        size = 7.5\n",
    "        if \"Sestan_DLPFC\" in file:\n",
    "            size = 6\n",
    "        sns.set(font_scale = 1.6)\n",
    "        sns.set_style(\"white\")\n",
    "        fig, ax = plt.subplots(figsize=(12,6))\n",
    "        ax = sns.stripplot(data=v, x = \"Comparison\", y=dist, hue = \"Cell type filtering\", palette = palette, dodge = True, size = size, order = comps, marker = shapes[\"_\".join(file.split(\"_\")[0:2])], linewidth=1)\n",
    "        t_ax = sns.barplot(data = dfp, x = \"Comparison\", y = \"Median rho\", hue = \"Neuron type\", dodge = True, errorbar=None, linewidth=2.5, edgecolor=\".5\", facecolor='#F2C91140', gap = 0.1, palette = palette, order = comps)\n",
    "    elif (\"ExprLevel\" == folder and \"ContTau\" not in file) or \"NotContExp\" in file:\n",
    "        size = 7.5\n",
    "        if \"Sestan_DLPFC\" in file:\n",
    "            size = 6\n",
    "        sns.set(font_scale = 1.6)\n",
    "        sns.set_style(\"white\")\n",
    "        fig, ax = plt.subplots(figsize=(12,6))\n",
    "        \n",
    "        if skip_sm:\n",
    "            v = v[~v[old_col_name].isin([\"No Filt Matched Size\"])]\n",
    "            dfp = dfp[~dfp[col_name].isin([\"No Filt Matched Size\"])]\n",
    "        ax = sns.stripplot(data=v, x = \"Comparison\", y=dist, hue = old_col_name, palette = palette_strat, dodge = True, size = size, order = comps, marker = shapes[\"_\".join(file.split(\"_\")[0:2])], linewidth=1)\n",
    "        t_ax = sns.barplot(data = dfp, x = \"Comparison\", y = \"Median rho\", hue = col_name, dodge = True, errorbar=None, linewidth=2.5, edgecolor=\".5\", facecolor='#F2C91140', gap = 0.1, palette = palette_strat, order = comps)\n",
    "    elif (\"ContExp\" in file and \"NotContExp\" not in file) or \"ContTau\" in file:\n",
    "        if skip_sm:\n",
    "            fig, ax = plt.subplots(figsize=(12,6))\n",
    "            sns.set(font_scale = 1.6)\n",
    "            sns.set_style(\"white\")\n",
    "            size = 7.5\n",
    "            if \"Sestan_DLPFC\" in file:\n",
    "                size = 6\n",
    "            if show_lm == \"Low\":\n",
    "                v = v[v[old_col_name].isin(['Low High', 'Low Low'])]\n",
    "                dfp = dfp[dfp[col_name].isin(['Low High', 'Low Low'])]\n",
    "            elif show_lm == \"Med\":\n",
    "                v = v[v[old_col_name].isin(['Med High', 'Med Med'])]\n",
    "                dfp = dfp[dfp[col_name].isin(['Med High', 'Med Med'])]\n",
    "            v[\"Sortby\"] = v[old_col_name].replace(iterer_d)\n",
    "            v = v.sort_values(\"Sortby\")\n",
    "            ax = sns.stripplot(data=v, x = \"Comparison\", y=dist, hue = old_col_name, palette = palette_strat_cont, dodge = True, size = size, order = comps, marker = shapes[\"_\".join(file.split(\"_\")[0:2])], linewidth=1)\n",
    "            t_ax = sns.barplot(data = dfp, x = \"Comparison\", y = \"Median rho\", hue = col_name, dodge = True, errorbar=None, linewidth=2.5, edgecolor=\".5\", facecolor='#F2C91140', gap = 0.1, palette = palette_strat_cont, order = comps)\n",
    "\n",
    "        else:\n",
    "            if \"Allen_MTG\" in file:\n",
    "                size = 5\n",
    "                fig, ax = plt.subplots(figsize=(18,6))\n",
    "                sns.set(font_scale = 1.5*1.6)\n",
    "                sns.set_style(\"white\")\n",
    "            else:\n",
    "                size = 6\n",
    "                if \"Sestan_DLPFC\" in file:\n",
    "                    size = 5\n",
    "                sns.set(font_scale = 1.6)\n",
    "                sns.set_style(\"white\")\n",
    "                fig, ax = plt.subplots(figsize=(12,6))\n",
    "            v[\"Sortby\"] = v[old_col_name].replace(iterer_d)\n",
    "            v = v.sort_values(\"Sortby\")\n",
    "            ax = sns.stripplot(data=v, x = \"Comparison\", y=dist, hue = old_col_name, palette = palette_strat_cont, dodge = True, size = size, order = comps, marker = shapes[\"_\".join(file.split(\"_\")[0:2])], linewidth=1)\n",
    "            t_ax = sns.barplot(data = dfp, x = \"Comparison\", y = \"Median rho\", hue = col_name, dodge = True, errorbar=None, linewidth=2.5, edgecolor=\".5\", facecolor='#F2C91140', gap = 0.1, palette = palette_strat_cont, order = comps)\n",
    "\n",
    "    #Change the colors of the bars and add asterisks to indicate significance\n",
    "    if folder == \"Vanilla\":\n",
    "        color_patches(t_ax, folder, dfp, comps, col_name)\n",
    "    \n",
    "    elif (folder == \"ExprLevel\" and \"ContTau\" not in file) or \"NotContExp\" in file:\n",
    "        color_patches(t_ax, folder, dfp, comps, col_name)\n",
    "        \n",
    "        #Compute whether correlations are significantly different using Fisher's method\n",
    "        dfp2 = compute_stats(comps, iterer, col_name, dfp_stats)\n",
    "    elif (\"ContExp\" in file and \"NotContExp\" not in file) or \"ContTau\" in file:\n",
    "        color_patches(t_ax, folder, dfp, comps, col_name, lm = show_lm, cont_exp = True)\n",
    "        \n",
    "        #Compute whether correlations are significantly different using Fisher's method\n",
    "        dfp2 = compute_stats(comps, iterer, col_name, dfp_stats, cont_exp = True)\n",
    "    \n",
    "    #Print or write out the statistics if needed\n",
    "    plt.xticks(rotation=45, horizontalalignment=\"right\")\n",
    "    plt.legend([], [], frameon = False)\n",
    "    plt.ylabel(\"Spearman correlation\")\n",
    "    if ax.get_ylim()[1] <= 0.1:\n",
    "        plt.ylim(ax.get_ylim()[0], 0.1)\n",
    "\n",
    "    if ctf == \"Exc\":\n",
    "        ct_title = \"excitatory\"\n",
    "    elif ctf == \"Inh\":\n",
    "        ct_title = \"inhibitory\"\n",
    "    else:\n",
    "        ct_title = \"all\"\n",
    "        \n",
    "    if \"subtype\" in file or \"cross_species_cluster\" in file:\n",
    "        resol = \"subtype\"\n",
    "    else:\n",
    "        resol = \"subclass\"\n",
    "    \n",
    "    if folder == \"ExprLevel\":\n",
    "        strat = \"expression level\"\n",
    "    elif folder == \"Pritchard\":\n",
    "        strat = \"constraint\"\n",
    "    elif folder == \"Tau\":\n",
    "        strat = \"tau\"\n",
    "    if folder != \"Vanilla\":\n",
    "        if (\"ContExp\" in file and \"NotContExp\" not in file) or \"ContTau\" in file:\n",
    "            strat = \"tau\"\n",
    "            plt.title(\"Stratifying by \" + strat + \", controlling for expr. level, \" + resol + \" resolution, \" + ct_title + \" neurons\")\n",
    "        else:\n",
    "            plt.title(\"Stratifying by \" + strat + \", \" + resol + \" resolution, \" + ct_title + \" neurons\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6944642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Go through making a bunch of plots, can change the lists to make different plots\n",
    "for j in [\"subclass_label\", \"cross_species_cluster_label\"]:\n",
    "    for i in [\"All\", \"Exc\", \"Inh\"]:\n",
    "        if \"subclass\" in j:\n",
    "            cell_num = 250\n",
    "        else:\n",
    "            cell_num = 50\n",
    "        ctp_swarmplot(\"Tau\", \"Allen_M1_\" + j + \"_NotAllSame_DownCounts1-100_General_ContExp_Tau.txt\", i, ncells = cell_num, dist_met = \"Euclidean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3da1fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in [\"subclass_label\", \"cross_species_cluster_label\"]:\n",
    "    for i in [\"All\", \"Exc\", \"Inh\"]:\n",
    "        if \"subclass\" in j:\n",
    "            cell_num = 250\n",
    "        else:\n",
    "            cell_num = 50\n",
    "        ctp_swarmplot(\"Tau\", \"Allen_M1_\" + j + \"_NotAllSame_DownCounts1-100_General_ContExp_Tau.txt\", i, ncells = cell_num, show_lm = \"Low\", dist_met = \"Euclidean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ac1a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decompose divergence along branches for human, chimp, and gorilla\n",
    "#Compute divergence of human relative to chimp as well\n",
    "\n",
    "out = []\n",
    "for i in range(1, 101):\n",
    "    vt = v[v[\"Iteration\"].isin([i])].copy()\n",
    "    \n",
    "    for ct in np.unique(vt[\"Cell type\"]):\n",
    "        vct = vt[vt[\"Cell type\"].isin([ct])].set_index(\"Comparison\")\n",
    "        dist_hc = vct.loc[\"Human-Chimp\"][\"Distance spearman\"]\n",
    "        dist_hg = vct.loc[\"Human-Gorilla\"][\"Distance spearman\"]\n",
    "        dist_cg = vct.loc[\"Gorilla-Chimp\"][\"Distance spearman\"]\n",
    "        div_h = (dist_hc + dist_hg - dist_cg)/2\n",
    "        div_c = (dist_hc + dist_cg - dist_hg)/2\n",
    "        div_g = (dist_hg - div_h)\n",
    "        out.append([ct, div_h, div_c, div_g, i])\n",
    "df = pd.DataFrame(out).sort_values(1)\n",
    "df.columns = [\"Cell type\", \"Human divergence\", \"Chimp divergence\", \"Gorilla divergence\", \"Iteration\"]\n",
    "out = []\n",
    "for ct in np.unique(df[\"Cell type\"]):\n",
    "    dfct = df[df[\"Cell type\"].isin([ct])]\n",
    "    out.append([ct, np.mean(dfct[\"Human divergence\"]), np.mean(dfct[\"Chimp divergence\"]), np.mean(dfct[\"Gorilla divergence\"])])\n",
    "df = pd.DataFrame(out)\n",
    "df.columns = [\"Cell type\", \"Human divergence\", \"Chimp divergence\", \"Gorilla divergence\"]\n",
    "df[\"Relative human divergence\"] = df[\"Human divergence\"]/df[\"Chimp divergence\"]\n",
    "df[\"Relative chimp divergence\"] = df[\"Chimp divergence\"]/df[\"Chimp divergence\"]\n",
    "df[\"Relative gorilla divergence\"] = df[\"Gorilla divergence\"]/df[\"Chimp divergence\"]\n",
    "\n",
    "df = df.sort_values(\"Relative human divergence\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bf731e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the cell type proportions\n",
    "\n",
    "file = \"Allen_MTG_subclass_NotAllSame_DownCounts1-100_General_distances.txt\"\n",
    "ctn = pd.read_csv(\"CellTypeNumbers/\" + file.split(\"_\" + ags)[0] + \"_CellTypeNumbers.txt\", sep = \"\\t\").set_index(\"Cell type\")\n",
    "ctn = ctn.loc[df[\"Cell type\"]]\n",
    "scomp = \"Human-Chimp\"\n",
    "for spec in scomp.split(\"-\"):\n",
    "    ctn[\"Proportion \" + spec] = ctn[\"Count \" + spec]/np.sum(ctn[\"Count \" + spec])\n",
    "ctn[\"Cell type proportion\"] = (ctn[\"Proportion \" + scomp.split(\"-\")[0]] + ctn[\"Proportion \" + scomp.split(\"-\")[1]])/2\n",
    "for i in list(ctn.columns):\n",
    "    if \"Count\" in i:\n",
    "        ctn = ctn[ctn[i] >= ncells]\n",
    "\n",
    "keep_cts = np.intersect1d(df[\"Cell type\"], ctn.index)\n",
    "df = df[df[\"Cell type\"].isin(keep_cts)].set_index(\"Cell type\")\n",
    "\n",
    "ctn = ctn.loc[keep_cts]\n",
    "df = df.join(ctn)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb13c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Similar to the ctp_regplot above, but for just human or chimp divergence and highlighting L2-5 IT neurons\n",
    "new_palette = {\"Human\":\"#FF2C0C\", \"Chimp\":\"#0058FF\", \"Rhesus\":\"#AD6D3E\", \"Marmoset\":\"#551A7F\", \"Gorilla\":\"#5C687D\"}\n",
    "new_palette_IT = {\"Chimp\":\"#00FFAC\", \"Human\":\"#F5E30E\"}\n",
    "plt.rcParams['xtick.major.size'] = 10\n",
    "plt.rcParams['xtick.major.width'] = 1.5\n",
    "plt.rcParams['xtick.minor.size'] = 4\n",
    "plt.rcParams['xtick.minor.width'] = 1\n",
    "plt.rcParams['xtick.bottom'] = True\n",
    "plt.rcParams['ytick.left'] = True\n",
    "\n",
    "def div_scatplot(v, to_plot = \"Human divergence\", ctf = \"All\"):\n",
    "    v[\"Log cell type proportion\"] = np.log10(v[\"Cell type proportion\"])\n",
    "    fig, ax = plt.subplots(figsize = (7, 5))\n",
    "    sns.set(font_scale = 1.6)\n",
    "    sns.set_style(\"white\")\n",
    "    v2 = v.loc[np.setdiff1d(v.index, [\"L2/3 IT\", \"L4 IT\", \"L5 IT\"])]\n",
    "    IT = []\n",
    "    for index, row in v.iterrows():\n",
    "        if index in [\"L2/3 IT\", \"L4 IT\", \"L5 IT\"]:\n",
    "            IT.append(\"L2-5 IT\")\n",
    "        else:\n",
    "            IT.append(\"Other\")\n",
    "    v[\"Subclass category\"] = IT\n",
    "    print(spearmanr(v[\"Cell type proportion\"], v[to_plot]))\n",
    "    print(spearmanr(v2[\"Cell type proportion\"], v2[to_plot]))\n",
    "    print(new_palette[to_plot.split(\" \")[0]])\n",
    "    ax = sns.regplot(data = v, x = \"Log cell type proportion\", y = to_plot, color = new_palette[to_plot.split(\" \")[0]], marker = shapes[\"_\".join(file.split(\"_\")[0:2])], scatter = False)\n",
    "    sns.scatterplot(data = v, x = \"Log cell type proportion\", y = to_plot, hue = \"Subclass category\", palette = {\"Other\":new_palette[to_plot.split(\" \")[0]], \"L2-5 IT\":new_palette_IT[to_plot.split(\" \")[0]]}, marker = shapes[\"_\".join(file.split(\"_\")[0:2])], edgecolors=\"black\")\n",
    "    \n",
    "    #print(spearmanr(v[\"Log cell type proportion\"], v[\"Distance spearman\"]))\n",
    "    ticks = ax.get_xticks()\n",
    "    print(ticks)\n",
    "    if \"subclass\" in file:\n",
    "        if \"All\" == ctf:\n",
    "            ticks = [-2, -1.5, -1, -0.5]\n",
    "            major_ticks2 = [0.01, 0.1]\n",
    "            major_ticks = [np.log10(x) for x in major_ticks2]\n",
    "            minor_ticks2 = [0.007, 0.008, 0.009, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.2, 0.3]\n",
    "            if \"Allen_M1\" in file:\n",
    "                minor_ticks2 = [0.009, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.2, 0.3]\n",
    "            minor_ticks = [np.log10(x) for x in minor_ticks2]\n",
    "            minor_ticks2 = ['' for x in minor_ticks2]\n",
    "        elif \"Inh\" == ctf or \"Exc\" == ctf:\n",
    "            ticks = [-1.5, -1, -0.5]\n",
    "            major_ticks2 = [0.03, 0.1, 0.3]\n",
    "            major_ticks = [np.log10(x) for x in major_ticks2]\n",
    "            minor_ticks2 = [0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.2, 0.3]\n",
    "            if \"Sestan_DLPFC\" in file:\n",
    "                if \"Exc\" in file:\n",
    "                    major_ticks2 = [0.01, 0.1, 0.3]\n",
    "                    major_ticks = [np.log10(x) for x in major_ticks2]\n",
    "                    minor_ticks2 = [0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.2, 0.3]\n",
    "                else:\n",
    "                    major_ticks2 = [0.03, 0.1, 0.3]\n",
    "                    major_ticks = [np.log10(x) for x in major_ticks2]\n",
    "                    minor_ticks2 = [0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.2, 0.3]\n",
    "            elif \"Allen_M1\" in file:\n",
    "                minor_ticks2 = [0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.2, 0.3]\n",
    "                if \"Inh\" == ctf:\n",
    "                    major_ticks2 = [0.05, 0.1, 0.3]\n",
    "                    major_ticks = [np.log10(x) for x in major_ticks2]\n",
    "                    minor_ticks2 = [0.05, 0.06, 0.07, 0.08, 0.09, 0.2, 0.3]\n",
    "            minor_ticks = [np.log10(x) for x in minor_ticks2]\n",
    "            minor_ticks2 = ['' for x in minor_ticks2]\n",
    "    elif \"subtype\" in file or \"cross_species_cluster\" in file:\n",
    "        if ctf == \"All\":\n",
    "            ticks = [-3, -2.5, -2, -1.5, -1]\n",
    "            major_ticks2 = [0.001, 0.01, 0.1]\n",
    "            major_ticks = [np.log10(x) for x in major_ticks2]\n",
    "            minor_ticks2 = [0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.2]\n",
    "            minor_ticks = [np.log10(x) for x in minor_ticks2]\n",
    "            minor_ticks2 = ['' for x in minor_ticks2]\n",
    "        elif ctf == \"Exc\":\n",
    "            ticks = [-2.5, -2, -1.5, -1, -0.5]\n",
    "            major_ticks2 = [0.002, 0.01, 0.1]\n",
    "            major_ticks = [np.log10(x) for x in major_ticks2]\n",
    "            minor_ticks2 = [0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.2]\n",
    "            minor_ticks = [np.log10(x) for x in minor_ticks2]\n",
    "            minor_ticks2 = ['' for x in minor_ticks2]\n",
    "        elif ctf == \"Inh\":\n",
    "            ticks = [-2.5, -2, -1.5, -1, -0.5]\n",
    "            major_ticks2 = [0.01, 0.1]\n",
    "            major_ticks = [np.log10(x) for x in major_ticks2]\n",
    "            minor_ticks2 = [0.005, 0.006, 0.007, 0.008, 0.009, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.2]\n",
    "            minor_ticks = [np.log10(x) for x in minor_ticks2]\n",
    "            minor_ticks2 = ['' for x in minor_ticks2]\n",
    "            if \"Sestan\" in file:\n",
    "                major_ticks2 = [0.01]\n",
    "                major_ticks = [np.log10(x) for x in major_ticks2]\n",
    "                minor_ticks2 = [0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08]\n",
    "                minor_ticks = [np.log10(x) for x in minor_ticks2]\n",
    "                minor_ticks2 = ['' for x in minor_ticks2]\n",
    "                ticks = [-2.5, -2, -1.5, -1]\n",
    "    \n",
    "    ax.set_xticks(major_ticks, major_ticks2, minor = False)\n",
    "    ax.set_xticks(minor_ticks, minor_ticks2, minor = True)\n",
    "\n",
    "    plt.xlabel(\"Cell type proportion\")\n",
    "    plt.title(\"Human branch divergence vs. cell type prop.\")\n",
    "    plt.ylabel(\"Human branch divergence\")\n",
    "    plt.legend(bbox_to_anchor = (1.5, 1))\n",
    "    \n",
    "    #Can uncomment this to get rid of the legend\n",
    "    #plt.legend([], [], frameon = False)\n",
    "div_scatplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eac2399",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the within human divergence\n",
    "df_save = pd.read_csv(\"WithinHuman_ToPlot.txt\", sep = \"\\t\").set_index(\"Cell type\")\n",
    "df_save = df_save.join(df).dropna()\n",
    "\n",
    "#Compute relative divegence to the human branch divergence\n",
    "df_save[\"Relative\"] = df_save[\"Human divergence\"]/(1-df_save[\"Mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3faeeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['mathtext.default'] = 'regular'\n",
    "df_save = df_save.sort_values(\"Relative\", ascending = False)\n",
    "\n",
    "\n",
    "#Plot, highlighting L2/3 IT\n",
    "fig, ax = plt.subplots(figsize = (7, 5))\n",
    "sns.set(font_scale = 1.6)\n",
    "sns.set_style(\"white\")\n",
    "df[\"H/C\"] = df[\"Human divergence\"]/df[\"Chimp divergence\"]\n",
    "IT = []\n",
    "df[\"Cell type\"] = df.index\n",
    "for index, row in df.iterrows():\n",
    "    if index in [\"L2/3 IT\"]:\n",
    "        IT.append(\"L2/3 IT\")\n",
    "    else:\n",
    "        IT.append(\"Other\")\n",
    "df[\"Subclass category\"] = IT\n",
    "sns.barplot(data = df, y=\"H/C\", x = \"Cell type\", hue = \"Subclass category\", palette = {\"L2/3 IT\": \"#FF2C0C\", \"Other\":\"#804285\"})\n",
    "plt.xticks(rotation = 90)\n",
    "plt.ylabel(r'$\\frac{Human{\\:}branch{\\:}divergence}{Chimp{\\:}branch{\\:}divergence}$', size = 30)\n",
    "#plt.title(\"Rapid evolution of L2/3 IT neurons in humans\")\n",
    "plt.ylim(1, 1.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a267ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot, highlighting L2/3 IT, for human branch vs within human\n",
    "\n",
    "IT = []\n",
    "df_save[\"Cell type\"] = df_save.index\n",
    "for index, row in df_save.iterrows():\n",
    "    if index in [\"L2/3 IT\"]:\n",
    "        IT.append(\"L2/3 IT\")\n",
    "    else:\n",
    "        IT.append(\"Other\")\n",
    "df_save[\"Subclass category\"] = IT\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (7, 5))\n",
    "sns.set(font_scale = 1.6)\n",
    "sns.set_style(\"white\")\n",
    "sns.barplot(data = df_save, y=\"Relative\", x = \"Cell type\", hue = \"Subclass category\", palette = {\"L2/3 IT\": \"#FF2C0C\", \"Other\":\"#804285\"})\n",
    "plt.xticks(rotation = 90)\n",
    "plt.ylabel(r'$\\frac{Human{\\:}branch{\\:}divergence}{Within{\\:}human{\\:}variability}$', size = 30)\n",
    "#plt.title(\"Rapid evolution of L2/3 IT neurons in humans\")\n",
    "plt.ylim(0.4, 0.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
